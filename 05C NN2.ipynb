{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ! pip install -U sentence-transformers ","metadata":{"execution":{"iopub.status.busy":"2023-04-10T21:41:46.358968Z","iopub.execute_input":"2023-04-10T21:41:46.359679Z","iopub.status.idle":"2023-04-10T21:41:46.365116Z","shell.execute_reply.started":"2023-04-10T21:41:46.359642Z","shell.execute_reply":"2023-04-10T21:41:46.363784Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-10T21:41:46.377716Z","iopub.execute_input":"2023-04-10T21:41:46.378470Z","iopub.status.idle":"2023-04-10T21:41:46.402962Z","shell.execute_reply.started":"2023-04-10T21:41:46.378439Z","shell.execute_reply":"2023-04-10T21:41:46.401862Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"/kaggle/input/reddit-mental-health-v2/train_roberta.npy\n/kaggle/input/reddit-mental-health-v2/crawl_matrix_reddit_mental_health_cut_v2.npy\n/kaggle/input/reddit-mental-health-v2/crawl_oov_reddit_mental_health_cut_v3.pickle\n/kaggle/input/reddit-mental-health-v2/crawl_oov_reddit_mental_health_cut.pickle\n/kaggle/input/reddit-mental-health-v2/crawl_matrix_reddit_mental_health_cut.npy\n/kaggle/input/reddit-mental-health-v2/test_df_cut.csv\n/kaggle/input/reddit-mental-health-v2/test_df_cut_processed_v2.csv\n/kaggle/input/reddit-mental-health-v2/cleaned_reddit.csv\n/kaggle/input/reddit-mental-health-v2/train_df_cut.csv\n/kaggle/input/reddit-mental-health-v2/test_roberta.npy\n/kaggle/input/reddit-mental-health-v2/train_df_cut_processed_v2.csv\n/kaggle/input/reddit-mental-health-v2/crawl_matrix_reddit_mental_health_cut_v3.npy\n/kaggle/input/reddit-mental-health-v2/cleaned_reddit_lemmatized.csv\n/kaggle/input/reddit-mental-health-v2/test_df_cut_processed.csv\n/kaggle/input/reddit-mental-health-v2/crawl_oov_reddit_mental_health_cut_v2.pickle\n/kaggle/input/reddit-mental-health-v2/crawl_matrix_reddit_mental_health_cut_v4.npy\n/kaggle/input/reddit-mental-health-v2/mental_health_sentence_embedding.pickle\n/kaggle/input/reddit-mental-health-v2/train_df_cut_processed.csv\n/kaggle/input/paragram-300-sl999/paragram_300_sl999.txt\n/kaggle/input/elmo-pretrained-embedding-eng-wiki/README\n/kaggle/input/elmo-pretrained-embedding-eng-wiki/options.json\n/kaggle/input/elmo-pretrained-embedding-eng-wiki/meta.json\n/kaggle/input/elmo-pretrained-embedding-eng-wiki/model.hdf5\n/kaggle/input/elmo-pretrained-embedding-eng-wiki/vocab.txt\n/kaggle/input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\n/kaggle/input/entxt1/en.txt\n/kaggle/input/glove840b300dtxt/glove.840B.300d.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\nimport unidecode\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport time\nimport torch.nn.functional as F\nfrom keras.preprocessing import text # depreciated?\nfrom torch.utils.data import Dataset, DataLoader,TensorDataset\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.utils import pad_sequences # new\nimport gc\nimport re\nimport pickle\nimport csv\nfrom tqdm import tqdm\ntqdm.pandas()\nfrom gensim.models import KeyedVectors\nfrom flashtext import KeywordProcessor\n\nCRAWL_EMBEDDING_PATH = '../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec'\nPARAD_EMBEDDING_PATH = '../input/paragram-dandrocec/paragram_300_sl999.txt'\nGLOVE_EMBEDDING_PATH = '../input/glove840b300dtxt/glove.840B.300d.txt'\n\nBATCH_SIZE = 256\nEPOCHS = 5\nMAX_LEN = 220\nNUM_MODEL = 3\nSEED = 6089","metadata":{"execution":{"iopub.status.busy":"2023-04-10T21:41:46.404836Z","iopub.execute_input":"2023-04-10T21:41:46.405594Z","iopub.status.idle":"2023-04-10T21:41:46.414766Z","shell.execute_reply.started":"2023-04-10T21:41:46.405552Z","shell.execute_reply":"2023-04-10T21:41:46.413762Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=SEED):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\nseed_everything()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T21:41:46.416841Z","iopub.execute_input":"2023-04-10T21:41:46.418067Z","iopub.status.idle":"2023-04-10T21:41:46.426426Z","shell.execute_reply.started":"2023-04-10T21:41:46.418030Z","shell.execute_reply":"2023-04-10T21:41:46.425442Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"def get_coefs(word, *arr):\n    return word, np.asarray(arr, dtype='float32')\n\ndef load_embeddings(path):\n    with open(path, encoding=\"utf8\", errors='ignore') as f:\n        return dict(get_coefs(*line.strip().split(' ')) for line in f)\n\ndef build_matrix(word_index, path):\n\n    \"\"\"\n    https://www.kaggle.com/bminixhofer/simple-lstm-pytorch-version\n    \"\"\"\n\n    embedding_index = load_embeddings(path)\n    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n#     unknown_vector = np.zeros((300,), dtype=np.float32) - 1.\n    \n    unknown_words = []\n\n    for word, i in word_index.items():\n        \n        if word in embedding_index:\n            embedding_matrix[i] = embedding_index[word]\n            continue\n        if word.upper() in embedding_index:\n            embedding_matrix[i] = embedding_index[word.upper()]\n            continue\n        if word.capitalize() in embedding_index:\n            embedding_matrix[i] = embedding_index[word.capitalize()]\n            continue\n        if unidecode.unidecode(word) in embedding_index:\n            embedding_matrix[i] = embedding_index[unidecode.unidecode(word)]\n            continue\n        if word.title() in embedding_index:\n            embedding_matrix[i] = embedding_index[word.title()]\n            continue\n        word = re.sub('[0-9]', '', word)\n        if word in embedding_index:\n            embedding_matrix[i] = embedding_index[word]\n            continue\n        \n#         embedding_matrix[i] = unknown_vector\n        unknown_words.append(word)\n            \n    return embedding_matrix, unknown_words","metadata":{"execution":{"iopub.status.busy":"2023-04-10T21:41:46.429403Z","iopub.execute_input":"2023-04-10T21:41:46.430231Z","iopub.status.idle":"2023-04-10T21:41:46.441206Z","shell.execute_reply.started":"2023-04-10T21:41:46.430190Z","shell.execute_reply":"2023-04-10T21:41:46.440200Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"def custom_loss(data, targets):\n\n    ''' Define custom loss function for weighted BCE on 'target' column '''\n    bce_loss = nn.BCELoss(weight=targets[:,1])(data[:,0],targets[:,0])\n    return bce_loss","metadata":{"execution":{"iopub.status.busy":"2023-04-10T21:41:46.443531Z","iopub.execute_input":"2023-04-10T21:41:46.443952Z","iopub.status.idle":"2023-04-10T21:41:46.452058Z","shell.execute_reply.started":"2023-04-10T21:41:46.443914Z","shell.execute_reply":"2023-04-10T21:41:46.450969Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# SWEAR_WORDS_PATH = '../input/entxt1/en.txt'\n\n# swear_words = []\n# with open(SWEAR_WORDS_PATH, 'r') as f:\n#     for token in f:\n#         swear_words.append(re.sub('\\n', '', token))\n# swear_words.extend(['<q>', '<a>', '<s>', '<x>', '<c>', '<b>','<n>', 'trump'])\n\n\npunc_sign = r\"\\ə\\ᴵ\\'∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&\\\\…\\/\\{\\}\\''\\[\\]\\_\\/\\@\\$\\%\\^\\&\\*\\(\\)\\+\\#\\:\\!\\-\\;\\!\\\"\\\\(\\),\\.?'+`~$=|•！？。＂＃＄％＆＇（）＊＋，－／：；<>＜＝＞＠［＼］＾＿｀｛｜｝～｟｠｢｣､、〃》「」『』【】〔〕〖〗〘〙〚〛〜〝〞〟〰〾〿–—‘’‛“”„‟‧﹏\"\n\n\nmispell_dict = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', \n                'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor', \n                'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ', \n                'qoura': 'quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', \n                'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much', 'howmany': 'how many', 'em': 'them',\n                'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', 'mastrubation': 'masturbation', \n                'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'etherium': 'ethereum', \n                'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', '2k19':'2019', 'qouta': 'quota', \n                'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', \n                'demonitisation': 'demonetization', 'demonitization': 'demonetization', \n                'demonetisation': 'demonetization', 'pokémon': 'pokemon', 'n*gga':'nigga', 'p*':'pussy', \n                'b***h':'bitch', 'a***h****':'asshole', 'a****le-ish':'asshole', 'b*ll-s***':'bullshit', 'd*g':'dog', \n                'st*up*id':'stupid','d***':'dick','di**':'dick',\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\",\n                \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \n                \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \n                \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \n                \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \n                \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\n                \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n                \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\",\n                \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n                \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\n                \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\",\n                \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\",\n                \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\",\n                \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\",\n                \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\",\n                \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", 'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling',\n                'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ', 'Qoura': 'Quora',\n                'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best',\n                'howdoes': 'how does', 'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data',\n                '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization',\n                'demonitization': 'demonetization', 'demonetisation': 'demonetization','\\u200b': ' ', '\\ufeff': '', 'करना': '', 'है': '',\n                'sh*tty': 'shitty','s**t':'shit',\n                'nigg*r':'nigger','bulls**t':'bullshit','n*****':'nigger',\n                'p*ssy':'pussy','p***y':'pussy',\n                'f***':'fuck','f*^k':'fuck','f*cked':'fucked','f*ck':'fuck','f***ing':'fucking',\n                'sh*t':'shit', 'su*k':'suck', 'a**holes':'assholes','a**hole':'asshole',\n                'di*k':'dick', 'd*ck': 'dick', 'd**k':'dick', 'd***':'dick',\n                'bull**it':'bullshit', 'c**t':'cunt', 'cu*t':'cunt', 'c*nt':'cunt','troʊl':'trool',\n                'trumpian':'bombast','realdonaldtrump':'trump','drumpf':'trump','trumpist':'trump',\n                \"i'ma\": \"i am\",\"is'nt\": \"is not\",\"‘I\":'I',\n                'ᴀɴᴅ':'and','ᴛʜᴇ':'the','ʜᴏᴍᴇ':'home','ᴜᴘ':'up','ʙʏ':'by','ᴀᴛ':'at','…and':'and','civilbeat':'civil beat',\\\n                'TrumpCare':'Trump care','Trumpcare':'Trump care', 'OBAMAcare':'Obama care','ᴄʜᴇᴄᴋ':'check','ғᴏʀ':'for','ᴛʜɪs':'this','ᴄᴏᴍᴘᴜᴛᴇʀ':'computer',\\\n                'ᴍᴏɴᴛʜ':'month','ᴡᴏʀᴋɪɴɢ':'working','ᴊᴏʙ':'job','ғʀᴏᴍ':'from','Sᴛᴀʀᴛ':'start','gubmit':'submit','CO₂':'carbon dioxide','ғɪʀsᴛ':'first',\\\n                'ᴇɴᴅ':'end','ᴄᴀɴ':'can','ʜᴀᴠᴇ':'have','ᴛᴏ':'to','ʟɪɴᴋ':'link','ᴏғ':'of','ʜᴏᴜʀʟʏ':'hourly','ᴡᴇᴇᴋ':'week','ᴇɴᴅ':'end','ᴇxᴛʀᴀ':'extra',\\\n                'Gʀᴇᴀᴛ':'great','sᴛᴜᴅᴇɴᴛs':'student','sᴛᴀʏ':'stay','ᴍᴏᴍs':'mother','ᴏʀ':'or','ᴀɴʏᴏɴᴇ':'anyone','ɴᴇᴇᴅɪɴɢ':'needing','ᴀɴ':'an','ɪɴᴄᴏᴍᴇ':'income',\\\n                'ʀᴇʟɪᴀʙʟᴇ':'reliable','ғɪʀsᴛ':'first','ʏᴏᴜʀ':'your','sɪɢɴɪɴɢ':'signing','ʙᴏᴛᴛᴏᴍ':'bottom','ғᴏʟʟᴏᴡɪɴɢ':'following','Mᴀᴋᴇ':'make',\\\n                'ᴄᴏɴɴᴇᴄᴛɪᴏɴ':'connection','ɪɴᴛᴇʀɴᴇᴛ':'internet','financialpost':'financial post', 'ʜaᴠᴇ':' have ', 'ᴄaɴ':' can ', 'Maᴋᴇ':' make ', 'ʀᴇʟɪaʙʟᴇ':' reliable ', 'ɴᴇᴇᴅ':' need ',\n                'ᴏɴʟʏ':' only ', 'ᴇxᴛʀa':' extra ', 'aɴ':' an ', 'aɴʏᴏɴᴇ':' anyone ', 'sᴛaʏ':' stay ', 'Sᴛaʀᴛ':' start', 'SHOPO':'shop','ᴀ':'A',\n                'theguardian':'the guardian','deplorables':'deplorable', 'theglobeandmail':'the globe and mail', 'justiciaries': 'justiciary','creditdation': 'Accreditation',\n                'doctrne':'doctrine','fentayal': 'fentanyl','designation-': 'designation','CONartist' : 'con-artist','Mutilitated' : 'Mutilated','Obumblers': 'bumblers',\n                'negotiatiations': 'negotiations','dood-': 'dood','irakis' : 'iraki','cooerate': 'cooperate','COx':'cox','racistcomments':'racist comments','envirnmetalists': 'environmentalists',\n                'SB91':'senate bill','tRump':'trump','utmterm':'utm term','FakeNews':'fake news','Gʀᴇat':'great','ʙᴏᴛtoᴍ':'bottom','washingtontimes':'washington times','garycrum':'gary crum','htmlutmterm':'html utm term',\n                'RangerMC':'car','TFWs':'tuition fee waiver','SJWs':'social justice warrior','Koncerned':'concerned','Vinis':'vinys','Yᴏᴜ':'you',\n                'trumpists': 'trump', 'trumpkins': 'trump','trumpism': 'trump','trumpsters':'trump','thedonald':'trump',\n                'trumpty': 'trump', 'trumpettes': 'trump','trumpland': 'trump','trumpies':'trump','trumpo':'trump',\n                'drump': 'trump', 'dtrumpview': 'trump','drumph': 'trump','trumpanzee':'trump','trumpite':'trump',\n                'chumpsters': 'trump', 'trumptanic': 'trump', 'itʻs': 'it is', 'donʻt': 'do not','pussyhats':'pussy hats',\n                'trumpdon': 'trump', 'trumpisms': 'trump','trumperatti':'trump', 'legalizefreedom': 'legalize freedom',\n                'trumpish': 'trump', 'ur': 'you are','twitler':'twitter','trumplethinskin':'trump','trumpnuts':'trump','trumpanzees':'trump',\n                'justmaybe':'just maybe','trumpie':'trump','trumpistan':'trump','trumphobic':'trump','piano2':'piano','trumplandia':'trump',\n                'globalresearch':'global research','trumptydumpty':'trump','frank1':'frank','trumpski':'trump','trumptards':'trump',\n                'alwaysthere':'always there','clickbait':'click bait','antifas':'antifa','dtrump':'trump','trumpflakes':'trump flakes',\n                'trumputin':'trump putin','fakesarge':'fake sarge','civilbot':'civil bot','tumpkin':'trump','trumpians':'trump',\n                'drumpfs':'trump','dtrumpo':'trump','trumpistas':'trump','trumpity':'trump','trump nut':'trump','tumpkin':'trump',\n                'russiagate':'russia gate','trumpsucker':'trump sucker','trumpbart':'trump bart', 'trumplicrat':'trump','dtrump0':'trump',\n                'tfixstupid':'stupid','brexit':'<a>','Brexit':'<a>',\n               }\n               \n\nmispell_dict2 = {'americanophobia': '<q>', 'klastri':'<s>','thisisurl':'url','magaphants':'<x>','cheetolini':'<c>','daesh':'<b>',\n                'trumpelthinskin':'<n>'}\nemoji_re = re.compile(u'['\n                        u'\\U00010000-\\U0010ffff' \n                        u'\\U0001F600-\\U0001F64F'\n                        u'\\U0001F300-\\U0001F5FF'\n                        u'\\U0001F30D-\\U0001F567'\n                        u'\\U0001F680-\\U0001F6FF'\n                        u'\\u2122-\\u2B55]', re.UNICODE)\n\nkp = KeywordProcessor(case_sensitive=True)\n                \nmix_mispell_dict = {}\nfor k, v in mispell_dict.items():\n    mix_mispell_dict[k] = v\n    mix_mispell_dict[k.lower()] = v.lower()\n    mix_mispell_dict[k.upper()] = v.upper()\n    mix_mispell_dict[k.capitalize()] = v.capitalize()\n    mix_mispell_dict[k.title()] = v.title()\n    \nfor k, v in mix_mispell_dict.items():\n    kp.add_keyword(k, v)    \n    \n\nkp2 = KeywordProcessor(case_sensitive=True)\nfor k, v in mispell_dict2.items():\n    kp2.add_keyword(k, v)\n    \n\ndef statistics_upper_words(text):\n    upper_count = 0\n    for token in text.split():\n        if re.search(r'[A-Z]', token):\n            upper_count += 1\n    return upper_count\n\ndef statistics_unique_words(text):\n    words_set = set()\n\n    for token in text.split():\n        words_set.add(token)\n\n    return len(words_set)\n\ndef statistics_characters_nums(text):\n\n    chars_set = set()\n\n    for char in text:\n        chars_set.add(char)\n    \n    return len(chars_set)\n\ndef statistics_swear_words(text):\n    swear_count = 0\n    for swear_word in swear_words:\n        if swear_word in text:\n            swear_count += 1\n    return swear_count\n\npuncts = [',', '.', '\"', ':', ')', '(', '!', '?', '|', ';', \"'\", '$', '&',\n    '/', '[', ']', '>', '%', '=', '#', '+', '\\\\', '•',  '~', '@', '£',\n    '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',\n    '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '“', '★', '”',\n    '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾',\n    '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼', '⊕', '▼',\n    '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲',\n    'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»',\n    '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø',\n    '¹', '≤', '‡', '√', '«', '»', '´', 'º', '¾', '¡', '§', '£', '₤', 'ə', '√',\n    'ᴵ', '∞', 'θ', '÷', 'α', '•', 'à', '−', 'β', '∅', '³', 'π', '‘', '₹', '´', '£', '€',\n    '×','™', '√', '²', '—', '…', ':', ';', '•', '！', '?', '$', '＄', '％', '＆', '（', '）']\n\ndef clean_text(x):\n    x = str(x)\n    for punct in puncts:\n        x = x.replace(punct, f' {punct} ')\n    return x\n    \n    \ndef content_preprocessing(text):\n    \n    text = text.lower()\n    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' thisisurl ', text)\n    text = kp.replace_keywords(text)\n    # text = re.sub(\"[%s]+\" %punc_sign , ' ' ,text)\n    text = clean_text(text)\n    emoji_num = len(emoji_re.findall(text))\n    text = emoji_re.sub(' ', text)\n    text = kp2.replace_keywords(text)\n    text = re.sub(r'\\s{2,}', ' ', text)\n    text = re.sub(r'\\n|\\t', '', text)\n    # upper_count = statistics_upper_words(text)\n    # characters_num = statistics_characters_nums(text)\n    # unique_words_num = statistics_unique_words(text)\n    # swear_words_num = statistics_swear_words(text)\n    \n    return text # , swear_words_num, len(text.split()), emoji_num, upper_count, unique_words_num, characters_num\n    ","metadata":{"execution":{"iopub.status.busy":"2023-04-10T21:41:46.660222Z","iopub.execute_input":"2023-04-10T21:41:46.660846Z","iopub.status.idle":"2023-04-10T21:41:46.717126Z","shell.execute_reply.started":"2023-04-10T21:41:46.660785Z","shell.execute_reply":"2023-04-10T21:41:46.716006Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# class Attention(nn.Module):\n#     def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n#         super(Attention, self).__init__(**kwargs)\n\n#         self.supports_masking = True\n#         self.bias = bias\n#         self.feature_dim = feature_dim\n#         self.step_dim = step_dim\n#         self.features_dim = 0\n\n#         weight = torch.zeros(feature_dim, 1)\n#         nn.init.xavier_uniform_(weight)\n#         self.weight = nn.Parameter(weight)\n\n#         if bias:\n#             self.b = nn.Parameter(torch.zeros(1))\n\n#     def forward(self, x, mask=None):\n\n#         feature_dim = self.feature_dim\n#         step_dim = self.step_dim\n        \n#         eij = torch.mm(\n#                 x.contiguous().view(-1, feature_dim), \n#                 self.weight\n#         ).view(-1, step_dim)\n\n#         if self.bias:\n#                 eij = eij + self.b\n\n#         eij = torch.tanh(eij)\n#         a = torch.exp(eij)\n\n#         if mask is not None:\n#             a = a * mask\n\n#         a = a / torch.sum(a, 1, keepdim=True) + 1e-10\n#         weighted_input = x * torch.unsqueeze(a, -1)\n#         return torch.sum(weighted_input, 1)\n\n# class SpatialDropout(nn.Module):\n\n#     def __init__(self,p):\n#         super(SpatialDropout, self).__init__()\n#         self.dropout = nn.Dropout2d(p)\n\n#     def forward(self, x):\n\n#             x = x.permute(0, 2, 1)   # convert to [batch, feature, timestep]\n#             x = self.dropout(x)\n#             x = x.permute(0, 2, 1)   # back to [batch, timestep, feature]\n#             return x\n\n# class NeuralNet(nn.Module):\n\n#     def __init__(self,embedding_matrix, num_unit, num_heads):\n#         super(NeuralNet, self).__init__()\n#         self.max_feature = embedding_matrix.shape[0]\n#         self.embedding_size = embedding_matrix.shape[1]\n#         self.embedding = nn.Embedding(self.max_feature, self.embedding_size)\n#         self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n#         self.embedding.weight.requires_grad = False\n#         self.embedding_dropout = SpatialDropout(0.1)\n#         self.lstm1 = nn.LSTM(self.embedding_size, num_unit, bidirectional=True, batch_first=True)\n#         self.lstm2 = nn.LSTM(num_unit*2, int(num_unit/2), bidirectional=True, batch_first=True)\n#         self.attention = Attention(num_unit, MAX_LEN)\n#         self.linear1 = nn.Linear(num_unit*3, num_unit)\n#         self.linear_out = nn.Linear(num_unit, 1)\n#         self.cat_linear = nn.Linear(1024, num_unit*3)\n#         self.multihead_attn = nn.MultiheadAttention(num_unit*3, num_heads, batch_first=True)\n        \n#     def forward(self, x, cat_embedding):\n\n#         h_embedding = self.embedding(x)\n#         h_embedding = self.embedding_dropout(h_embedding)\n#         h_lstm1, _ = self.lstm1(h_embedding)\n#         h_lstm2, _ = self.lstm2(h_lstm1) # 512,300,2*num_unit\n\n#         # attention\n#         att = self.attention(h_lstm2)\n\n#         # global average pooling\n#         avg_pool = torch.mean(h_lstm2, 1)\n\n#         # global max pooling\n#         max_pool, _ = torch.max(h_lstm2, 1)\n        \n#         # concatenation\n#         h = torch.cat((max_pool, avg_pool, att), 1) ### concat or h equal Q/V   # orignal: num_unit*3\n#         h_flat = torch.unsqueeze(h, -1).permute(0, 2, 1)\n        \n#         category_embedding = self.cat_linear(cat_embedding)\n        \n#         attn_output, attn_output_weights = self.multihead_attn(category_embedding, h_flat, h_flat)\n#         # attn_output = torch.squeeze(attn_output)\n\n#         avg_pool_attn = torch.mean(attn_output, 1)\n\n#         # post 也可不用過sentmodel\n#         # k -> sentence model 得到contextual embedding \n#         # attn_output, attn_weights拿來驗證\n        \n#         h_linear1 = F.relu(self.linear1(avg_pool_attn))\n#         # h_linear1 = F.relu(self.linear1(torch.cat((h, avg_pool_attn), 1)))\n\n#         out1 = torch.sigmoid(self.linear_out(h_linear1))\n\n#         return out1","metadata":{"execution":{"iopub.status.busy":"2023-04-10T21:41:46.719620Z","iopub.execute_input":"2023-04-10T21:41:46.720031Z","iopub.status.idle":"2023-04-10T21:41:46.730219Z","shell.execute_reply.started":"2023-04-10T21:41:46.719982Z","shell.execute_reply":"2023-04-10T21:41:46.729246Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# class Attention(nn.Module):\n#     def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n#         super(Attention, self).__init__(**kwargs)\n\n#         self.supports_masking = True\n#         self.bias = bias\n#         self.feature_dim = feature_dim\n#         self.step_dim = step_dim\n#         self.features_dim = 0\n\n#         weight = torch.zeros(feature_dim, 1)\n#         nn.init.xavier_uniform_(weight)\n#         self.weight = nn.Parameter(weight)\n\n#         if bias:\n#             self.b = nn.Parameter(torch.zeros(1))\n\n#     def forward(self, x, mask=None):\n\n#         feature_dim = self.feature_dim\n#         step_dim = self.step_dim\n        \n#         eij = torch.mm(\n#                 x.contiguous().view(-1, feature_dim), \n#                 self.weight\n#         ).view(-1, step_dim)\n\n#         if self.bias:\n#                 eij = eij + self.b\n\n#         eij = torch.tanh(eij)\n#         a = torch.exp(eij)\n\n#         if mask is not None:\n#             a = a * mask\n\n#         a = a / torch.sum(a, 1, keepdim=True) + 1e-10\n#         weighted_input = x * torch.unsqueeze(a, -1)\n#         return torch.sum(weighted_input, 1)\n\n# class SpatialDropout(nn.Module):\n\n#     def __init__(self,p):\n#         super(SpatialDropout, self).__init__()\n#         self.dropout = nn.Dropout2d(p)\n\n#     def forward(self, x):\n\n#             x = x.permute(0, 2, 1)   # convert to [batch, feature, timestep]\n#             x = self.dropout(x)\n#             x = x.permute(0, 2, 1)   # back to [batch, timestep, feature]\n#             return x\n\n# class NeuralNet(nn.Module):\n\n#     def __init__(self,embedding_matrix, num_unit, num_heads):\n#         super(NeuralNet, self).__init__()\n#         self.max_feature = embedding_matrix.shape[0]\n#         self.embedding_size = embedding_matrix.shape[1]\n#         self.embedding = nn.Embedding(self.max_feature, self.embedding_size)\n#         self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n#         self.embedding.weight.requires_grad = False\n#         self.embedding_dropout = SpatialDropout(0.1)\n#         self.lstm1 = nn.LSTM(self.embedding_size, num_unit, bidirectional=True, batch_first=True)\n#         self.lstm2 = nn.LSTM(num_unit*2, int(num_unit/2), bidirectional=True, batch_first=True)\n#         self.attention = Attention(num_unit, MAX_LEN)\n#         self.linear1 = nn.Linear(num_unit*6, num_unit)\n#         self.linear_out = nn.Linear(num_unit, 1)\n#         self.cat_linear = nn.Linear(1024, num_unit*3)\n#         self.multihead_attn = nn.MultiheadAttention(num_unit*3, num_heads, batch_first=True)\n        \n#     def forward(self, x, cat_embedding):\n\n#         h_embedding = self.embedding(x)\n#         h_embedding = self.embedding_dropout(h_embedding)\n#         h_lstm1, _ = self.lstm1(h_embedding)\n#         h_lstm2, _ = self.lstm2(h_lstm1) # 512,300,2*num_unit\n\n#         # attention\n#         att = self.attention(h_lstm2)\n\n#         # global average pooling\n#         avg_pool = torch.mean(h_lstm2, 1)\n\n#         # global max pooling\n#         max_pool, _ = torch.max(h_lstm2, 1)\n        \n#         # concatenation\n#         h = torch.cat((max_pool, avg_pool, att), 1) ### concat or h equal Q/V   # orignal: num_unit*3\n#         h_flat = torch.unsqueeze(h, -1).permute(0, 2, 1)\n        \n#         category_embedding = self.cat_linear(cat_embedding)\n        \n#         attn_output, attn_output_weights = self.multihead_attn(category_embedding, h_flat, h_flat)\n#         # attn_output = torch.squeeze(attn_output)\n\n#         avg_pool_attn = torch.mean(attn_output, 1)\n\n#         # post 也可不用過sentmodel\n#         # k -> sentence model 得到contextual embedding \n#         # attn_output, attn_weights拿來驗證\n        \n#         # h_linear1 = F.relu(self.linear1(avg_pool_attn))\n#         h_linear1 = F.relu(self.linear1(torch.cat((h, avg_pool_attn), 1)))\n\n#         out1 = torch.sigmoid(self.linear_out(h_linear1))\n\n#         return out1","metadata":{"execution":{"iopub.status.busy":"2023-04-10T21:41:46.732180Z","iopub.execute_input":"2023-04-10T21:41:46.732602Z","iopub.status.idle":"2023-04-10T21:41:46.743821Z","shell.execute_reply.started":"2023-04-10T21:41:46.732563Z","shell.execute_reply":"2023-04-10T21:41:46.742835Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n        super(Attention, self).__init__(**kwargs)\n\n        self.supports_masking = True\n        self.bias = bias\n        self.feature_dim = feature_dim\n        self.step_dim = step_dim\n        self.features_dim = 0\n\n        weight = torch.zeros(feature_dim, 1)\n        nn.init.xavier_uniform_(weight)\n        self.weight = nn.Parameter(weight)\n\n        if bias:\n            self.b = nn.Parameter(torch.zeros(1))\n\n    def forward(self, x, mask=None):\n\n        feature_dim = self.feature_dim\n        step_dim = self.step_dim\n        \n        eij = torch.mm(\n                x.contiguous().view(-1, feature_dim), \n                self.weight\n        ).view(-1, step_dim)\n\n        if self.bias:\n                eij = eij + self.b\n\n        eij = torch.tanh(eij)\n        a = torch.exp(eij)\n\n        if mask is not None:\n            a = a * mask\n\n        a = a / torch.sum(a, 1, keepdim=True) + 1e-10\n        weighted_input = x * torch.unsqueeze(a, -1)\n        return torch.sum(weighted_input, 1)\n\nclass SpatialDropout(nn.Module):\n\n    def __init__(self,p):\n        super(SpatialDropout, self).__init__()\n        self.dropout = nn.Dropout2d(p)\n\n    def forward(self, x):\n\n            x = x.permute(0, 2, 1)   # convert to [batch, feature, timestep]\n            x = self.dropout(x)\n            x = x.permute(0, 2, 1)   # back to [batch, timestep, feature]\n            return x\n\nclass NeuralNet(nn.Module):\n\n    def __init__(self,embedding_matrix, num_unit, num_heads):\n        super(NeuralNet, self).__init__()\n        self.max_feature = embedding_matrix.shape[0]\n        self.embedding_size = embedding_matrix.shape[1]\n        self.embedding = nn.Embedding(self.max_feature, self.embedding_size)\n        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n        self.embedding.weight.requires_grad = False\n        self.embedding_dropout = SpatialDropout(0.1)\n        self.lstm1 = nn.LSTM(self.embedding_size, num_unit, bidirectional=True, batch_first=True)\n        self.lstm2 = nn.LSTM(num_unit*2, int(num_unit/2), bidirectional=True, batch_first=True)\n        self.attention = Attention(num_unit, MAX_LEN)\n        self.linear1 = nn.Linear(num_unit*3+1024*2, num_unit)\n        self.linear_out = nn.Linear(num_unit, 1)\n        # self.cat_linear = nn.Linear(1024, num_unit)\n        self.multihead_attn = nn.MultiheadAttention(1024, num_heads, batch_first=True)\n        \n    def forward(self, x, x_context_embedding, cat_embedding):\n\n        h_embedding = self.embedding(x)\n        h_embedding = self.embedding_dropout(h_embedding)\n        h_lstm1, _ = self.lstm1(h_embedding)\n        h_lstm2, _ = self.lstm2(h_lstm1) # 512,300,2*num_unit\n        \n        # category_embedding = self.cat_linear(cat_embedding)\n        # attn_output, attn_output_weights = self.multihead_attn(category_embedding, h_lstm2, h_lstm2)\n        x_context_embedding = torch.unsqueeze(x_context_embedding, 1)\n        attn_output, attn_output_weights = self.multihead_attn(cat_embedding, x_context_embedding, x_context_embedding)\n        avg_pool_attn = torch.mean(attn_output, 1)\n        max_pool_attn, _ = torch.max(attn_output, 1)\n        \n        # attention\n        att = self.attention(h_lstm2)\n\n        # global average pooling\n        avg_pool = torch.mean(h_lstm2, 1)\n\n        # global max pooling\n        max_pool, _ = torch.max(h_lstm2, 1)\n        \n        # concatenation\n        # h = torch.cat((max_pool, avg_pool, att), 1) ### concat or h equal Q/V   # orignal: num_unit*3\n        h = torch.cat((max_pool, avg_pool, att, avg_pool_attn, max_pool_attn), 1) ### concat or h equal Q/V   # orignal: num_unit*3\n        # h_flat = torch.unsqueeze(h, -1).permute(0, 2, 1)\n        \n        # post 也可不用過sentmodel\n        # k -> sentence model 得到contextual embedding \n        # attn_output, attn_weights拿來驗證\n        \n        # h_linear1 = F.relu(self.linear1(avg_pool_attn))\n        h_linear1 = F.relu(self.linear1(h))\n\n        out1 = torch.sigmoid(self.linear_out(h_linear1))\n\n        return out1","metadata":{"execution":{"iopub.status.busy":"2023-04-10T21:41:46.862731Z","iopub.execute_input":"2023-04-10T21:41:46.863039Z","iopub.status.idle":"2023-04-10T21:41:46.881848Z","shell.execute_reply.started":"2023-04-10T21:41:46.863011Z","shell.execute_reply":"2023-04-10T21:41:46.880581Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"mental_health_groups = [\n    'EDAnonymous',\n    'addiction',\n    'alcoholism',\n    'adhd',\n    'anxiety',\n    'autism',\n    'bipolarreddit',\n    'bpd',\n    'depression',\n    'healthanxiety',\n    'lonely',\n    'ptsd',\n    'schizophrenia',\n    'socialanxiety',\n    'suicidewatch'\n]\n\nnon_mental_health = [\n    'conspiracy',\n    'divorce',\n    'fitness', \n    'guns', \n    'jokes', \n    'legaladvice', \n    'meditation', \n    'parenting', \n    'personalfinance', \n    'relationships', \n    'teaching',\n]","metadata":{"execution":{"iopub.status.busy":"2023-04-10T21:41:46.884613Z","iopub.execute_input":"2023-04-10T21:41:46.885440Z","iopub.status.idle":"2023-04-10T21:41:46.892758Z","shell.execute_reply.started":"2023-04-10T21:41:46.885401Z","shell.execute_reply":"2023-04-10T21:41:46.891453Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# # prepare simplified version of the reddit mental health dataset\n# mh_fnames = []\n# for g in mental_health_groups:\n#     mh_fnames.append(f'{g}_2018_features_tfidf_256.csv')\n#     mh_fnames.append(f'{g}_2019_features_tfidf_256.csv')\n#     mh_fnames.append(f'{g}_pre_features_tfidf_256.csv')\n#     mh_fnames.append(f'{g}_post_features_tfidf_256.csv')\n# mh_fnames.remove('EDAnonymous_2018_features_tfidf_256.csv')\n\n# path = '/kaggle/input/reddit-mental-health/'\n# all_fname = os.listdir(path)\n\n# df_mh = pd.DataFrame()\n# for f in mh_fnames:\n#     df_mh = df_mh.append(pd.read_csv(path + f))\n# df_mh = df_mh.reset_index(drop = True)\n\n# non_mh_fnames = []\n# for g in non_mental_health:\n#     non_mh_fnames.append(f'{g}_2018_features_tfidf_256.csv')\n#     non_mh_fnames.append(f'{g}_2019_features_tfidf_256.csv')\n#     non_mh_fnames.append(f'{g}_pre_features_tfidf_256.csv')\n#     non_mh_fnames.append(f'{g}_post_features_tfidf_256.csv')\n    \n# df_non_mh = pd.DataFrame()\n# for f in non_mh_fnames:\n#     df_non_mh = df_non_mh.append(pd.read_csv(path + f))\n# df_non_mh = df_non_mh.reset_index(drop = True)\n\n# df_mh['label'] = 1.0\n# df_non_mh['label'] = 0.0\n\n# extracted_col = []\n# for c in df_mh.columns:\n#     if not c.startswith('liwc') and not c.startswith('tfidf'):\n#         extracted_col.append(c)     \n# df_mh = df_mh.loc[:, extracted_col]\n\n# extracted_col = []\n# for c in df_non_mh.columns:\n#     if not c.startswith('liwc') and not c.startswith('tfidf'):\n#         extracted_col.append(c)     \n# df_non_mh = df_non_mh.loc[:, extracted_col]\n\n# df_train = df_mh.append(df_non_mh)\n# df_train = df_train.reset_index(drop = True)\n\n# df_train.to_csv('df_train.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T21:41:46.894380Z","iopub.execute_input":"2023-04-10T21:41:46.894844Z","iopub.status.idle":"2023-04-10T21:41:46.901939Z","shell.execute_reply.started":"2023-04-10T21:41:46.894773Z","shell.execute_reply":"2023-04-10T21:41:46.900828Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"# # Generate cut version (first 500 tokens) of training and testing data \n# df_train = pd.read_csv('/kaggle/input/reddit-mental-health-v2/df_train.csv')\n\n# df_train['post'] = df_train['post'].map(lambda x: ' '.join(x.split(' ')[:500]))\n\n# # shuffle the data\n# df_train = df_train.sample(len(df_train))\n\n# df_train = df_train.reset_index(drop = True)\n\n# df_train.to_csv('df_train_cut.csv', index = False)\n\n# train_df, test_df = train_test_split(df_train, test_size=0.20, random_state=5246)\n# train_df = train_df.reset_index(drop=True)\n# test_df = test_df.reset_index(drop=True)\n\n# train_df.to_csv('train_df_cut.csv', index = False)\n# test_df.to_csv('test_df_cut.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T21:41:46.904683Z","iopub.execute_input":"2023-04-10T21:41:46.905850Z","iopub.status.idle":"2023-04-10T21:41:46.914496Z","shell.execute_reply.started":"2023-04-10T21:41:46.905786Z","shell.execute_reply":"2023-04-10T21:41:46.913372Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# Start from here","metadata":{"execution":{"iopub.status.busy":"2023-04-10T21:41:46.916429Z","iopub.execute_input":"2023-04-10T21:41:46.917196Z","iopub.status.idle":"2023-04-10T21:41:46.925490Z","shell.execute_reply.started":"2023-04-10T21:41:46.917159Z","shell.execute_reply":"2023-04-10T21:41:46.924509Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# train_df = pd.read_csv('/kaggle/input/reddit-mental-health-v2/train_df_cut.csv')\n# test_df = pd.read_csv('/kaggle/input/reddit-mental-health-v2/test_df_cut.csv')","metadata":{"execution":{"iopub.status.busy":"2023-04-10T21:41:46.926956Z","iopub.execute_input":"2023-04-10T21:41:46.928042Z","iopub.status.idle":"2023-04-10T21:41:46.934905Z","shell.execute_reply.started":"2023-04-10T21:41:46.927873Z","shell.execute_reply":"2023-04-10T21:41:46.933649Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/reddit-mental-health-v2/cleaned_reddit_lemmatized.csv')","metadata":{"execution":{"iopub.status.busy":"2023-04-10T21:41:46.936436Z","iopub.execute_input":"2023-04-10T21:41:46.936982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df[~df[\"subreddit\"].isin([\"mentalhealth\", \"COVID19_support\"])]\ndf = df.groupby('subreddit', group_keys=False).apply(lambda x: x.sample(frac=0.6))\ndf['text_processed_trim'] = df['text_processed'].apply(lambda x: \" \".join(str(x).split(\" \")[:300]))\ndf = df.sort_values(by='date', ascending=True)\ndf = df.reset_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = df[df[\"date_year\"].isin([2018, 2019])]\ntest_df = df[df[\"date_year\"]==2020]\n\ntrain_df = train_df.reset_index(drop = True)\ntest_df = test_df.reset_index(drop = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # using a subset first to test\n# train_df = train_df.sample(2000)\n# test_df = test_df.sample(600)\n\n# train_df = train_df.reset_index(drop = True)\n# test_df = test_df.reset_index(drop = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape)\nprint(test_df.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### preprocessing\nx_train = train_df[\"post\"].apply(lambda x: content_preprocessing(x))\nx_test = test_df[\"post\"].apply(lambda x: content_preprocessing(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ### preprocessing\n# x_train = train_df[\"text_processed_trim\"]\n# x_test = test_df[\"text_processed_trim\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = text.Tokenizer(filters='', lower=False)\n# tokenizer.fit_on_texts(list(x_train))\ntokenizer.fit_on_texts(list(x_train)+list(x_test))\n\nx_train = tokenizer.texts_to_sequences(x_train)\nx_test = tokenizer.texts_to_sequences(x_test)\n\nx_train = pad_sequences(x_train, maxlen=MAX_LEN,padding='post')\nx_test = pad_sequences(x_test, maxlen=MAX_LEN,padding='post')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del tokenizer\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sentence_transformers import SentenceTransformer\n# # sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n# sentence_model = SentenceTransformer('all-roberta-large-v1', device='cuda')\n\n# sentence_model.max_seq_length = 154","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_roberta = np.load('/kaggle/input/reddit-mental-health-v2/train_roberta.npy')\ntest_roberta = np.load('/kaggle/input/reddit-mental-health-v2/test_roberta.npy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_roberta = sentence_model.encode(list(train_df['post']))\n# test_roberta = sentence_model.encode(list(test_df['post']))\n\n# np.save('train_roberta.npy', train_roberta)\n# np.save('test_roberta.npy', test_roberta) # save","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mental_health_description = {\n#     \"EDAnonymous\": \"An eating disorder is a mental disorder defined by abnormal eating behaviors that negatively affect a person's physical or mental health. Types of eating disorders include binge eating disorder, where the patient eats a large amount in a short period of time; anorexia nervosa, where the person has an intense fear of gaining weight and restricts food or overexercises to manage this fear; bulimia nervosa, where individuals eat a large quantity (binging) then try to rid themselves of the food (purging); pica, where the patient eats non-food items; rumination syndrome, where the patient regurgitates undigested or minimally digested food; avoidant/restrictive food intake disorder (ARFID), where people have a reduced or selective food intake due to some psychological reasons; and a group of other specified feeding or eating disorders. Anxiety disorders, depression and substance abuse are common among people with eating disorders. These disorders do not include obesity. People often experience comorbidity between an eating disorder and OCD. It is estimated 20-60% of patients with an ED have a history of OCD.\",\n#     \"addiction\": \"Addiction is generally a neuropsychological symptom defining pervasive and intense urge to engage in maladaptive behaviors providing immediate sensory rewards (e.g. consuming drugs, excessively gambling), despite their harmful consequences. Dependence is generally an addiction that can involve withdrawal issues. Addictive disorder is a category of mental disorders defining important intensities of addictions or dependences, which induce functional disabilities.\",\n#     \"adhd\": \"Attention deficit hyperactivity disorder (ADHD) is a neurodevelopmental disorder characterised by excessive amounts of inattention, hyperactivity, and impulsivity that are pervasive, impairing in multiple contexts, and otherwise age-inappropriate.\",\n#     \"alcoholism\": \"Alcoholism is, broadly, any drinking of alcohol that results in significant mental or physical health problems. Because there is disagreement on the definition of the word alcoholism, it is not a recognized diagnostic entity, and the use of alcoholism terminology is discouraged due to its heavily stigmatized connotations. Predominant diagnostic classifications are alcohol use disorder (DSM-5) or alcohol dependence (ICD-11); these are defined in their respective sources.\",\n#     \"anxiety\": \"Anxiety is an emotion which is characterized by an unpleasant state of inner turmoil and includes feelings of dread over anticipated events. Anxiety is different than fear in that the former is defined as the anticipation of a future threat whereas the latter is defined as the emotional response to a real threat. It is often accompanied by nervous behavior such as pacing back and forth, somatic complaints, and rumination.\",\n#     \"autism\": \"The autism spectrum, often referred to as just autism, autism spectrum disorder (ASD) or sometimes autism spectrum condition (ASC), identifies a loosely defined cluster of neurodevelopmental disorders characterized by challenges in social interaction, verbal and nonverbal communication, and often repetitive behaviors and restricted interests. Other common features include unusual responses to sensory stimuli and a preference for sameness or unusual adherence to routines.\",\n#     \"bipolarreddit\": \"Bipolar disorder, previously known as manic depression, is a mental disorder characterized by periods of depression and periods of abnormally elevated mood that each last from days to weeks. If the elevated mood is severe or associated with psychosis, it is called mania; if it is less severe, it is called hypomania. During mania, an individual behaves or feels abnormally energetic, happy or irritable, and they often make impulsive decisions with little regard for the consequences. There is usually also a reduced need for sleep during manic phases. During periods of depression, the individual may experience crying and have a negative outlook on life and poor eye contact with others. The risk of suicide is high; over a period of 20 years, 6% of those with bipolar disorder died by suicide, while 30–40% engaged in self-harm. Other mental health issues, such as anxiety disorders and substance use disorders, are commonly associated with bipolar disorder.\",\n#     \"bpd\": \"Borderline personality disorder (BPD), also known as emotionally unstable personality disorder (EUPD), is a personality disorder characterized by a long-term pattern of intense and unstable interpersonal relationships, distorted sense of self, and strong emotional reactions. Those affected often engage in self-harm and other dangerous behaviors, often due to their difficulty with returning their emotional level to a healthy or normal baseline. They may also struggle with a feeling of emptiness, fear of abandonment, and detachment from reality.\",\n#     \"depression\": \"Depression is a mental state of low mood and aversion to activity. It affects more than 280 million people of all ages (about 3.5% of the global population). Depression affects a person's thoughts, behavior, feelings, and sense of well-being. Depressed people often experience loss of motivation or interest in, or reduced pleasure or joy from, experiences that would normally bring them pleasure or joy. Depressed mood is a symptom of some mood disorders such as major depressive disorder and dysthymia; it is a normal temporary reaction to life events, such as the loss of a loved one; and it is also a symptom of some physical diseases and a side effect of some drugs and medical treatments. It may feature sadness, difficulty in thinking and concentration and a significant increase or decrease in appetite and time spent sleeping. People experiencing depression may have feelings of dejection or hopelessness and may experience suicidal thoughts. It can either be short term or long term.\",\n#     \"healthanxiety\": \"Hypochondriasis or hypochondria is a condition in which a person is excessively and unduly worried about having a serious illness. Hypochondria is an old concept whose meaning has repeatedly changed over its lifespan. It has been claimed that this debilitating condition results from an inaccurate perception of the condition of body or mind despite the absence of an actual medical diagnosis. An individual with hypochondriasis is known as a hypochondriac. Hypochondriacs become unduly alarmed about any physical or psychological symptoms they detect, no matter how minor the symptom may be, and are convinced that they have, or are about to be diagnosed with, a serious illness.\",\n#     \"lonely\": \"Loneliness is an unpleasant emotional response to perceived isolation. Loneliness is also described as social pain – a psychological mechanism which motivates individuals to seek social connections. It is often associated with a perceived lack of connection and intimacy. Loneliness overlaps and yet is distinct from solitude. Solitude is simply the state of being apart from others; not everyone who experiences solitude feels lonely. As a subjective emotion, loneliness can be felt even when a person is surrounded by other people. Hence, there is a distinction between being alone and feeling lonely. Loneliness can be short term (state loneliness) or long term (chronic loneliness). In either case, it can be intense and painful.\",\n#     \"ptsd\": \"Post-traumatic stress disorder (PTSD) is a mental and behavioral disorder that can develop because of exposure to a traumatic event, such as sexual assault, warfare, traffic collisions, child abuse, domestic violence, or other threats on a person's life. Symptoms may include disturbing thoughts, feelings, or dreams related to the events, mental or physical distress to trauma-related cues, attempts to avoid trauma-related cues, alterations in the way a person thinks and feels, and an increase in the fight-or-flight response. These symptoms last for more than a month after the event. Young children are less likely to show distress but instead may express their memories through play. A person with PTSD is at a higher risk of suicide and intentional self-harm.\",\n#     \"schizophrenia\": \"Schizophrenia is a mental disorder characterized by continuous or relapsing episodes of psychosis. Major symptoms include hallucinations (typically hearing voices), delusions, and disorganized thinking. Other symptoms include social withdrawal, decreased emotional expression, and apathy. Symptoms typically develop gradually, begin during young adulthood, and in many cases never become resolved. There is no objective diagnostic test; diagnosis is based on observed behavior, a psychiatric history that includes the person's reported experiences, and reports of others familiar with the person. To be diagnosed with schizophrenia, symptoms and functional impairment need to be present for six months (DSM-5) or one month (ICD-11). Many people with schizophrenia have other mental disorders, especially substance use disorders, depressive disorders, anxiety disorders, and obsessive–compulsive disorder.\",\n#     \"socialanxiety\": \"Social anxiety is the anxiety and fear specifically linked to being in social settings (i.e., interacting with others). Some categories of disorders associated with social anxiety include anxiety disorders, mood disorders, autism spectrum disorders, eating disorders, and substance use disorders. Individuals with higher levels of social anxiety often avert their gazes, show fewer facial expressions, and show difficulty with initiating and maintaining a conversation. Social anxiety commonly manifests itself in the teenage years and can be persistent throughout life, however, people who experience problems in their daily functioning for an extended period of time can develop social anxiety disorder. Trait social anxiety, the stable tendency to experience this anxiety, can be distinguished from state anxiety, the momentary response to a particular social stimulus. Half of the individuals with any social fears meet the criteria for social anxiety disorder. Age, culture, and gender impact the severity of this disorder. The function of social anxiety is to increase arousal and attention to social interactions, inhibit unwanted social behavior, and motivate preparation for future social situations.\",\n#     \"suicidewatch\": \"Suicide is the act of intentionally causing one's own death. Mental disorders (including depression, bipolar disorder, schizophrenia, personality disorders, anxiety disorders), physical disorders (such as chronic fatigue syndrome), and substance abuse (including alcoholism and the use of and withdrawal from benzodiazepines) are risk factors. Some suicides are impulsive acts due to stress (such as from financial or academic difficulties), relationship problems (such as breakups or divorces), or harassment and bullying. Those who have previously attempted suicide are at a higher risk for future attempts. Effective suicide prevention efforts include limiting access to methods of suicide such as firearms, drugs, and poisons; treating mental disorders and substance abuse; careful media reporting about suicide; and improving economic conditions. Although crisis hotlines are common resources, their effectiveness has not been well studied.\",\n# }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mental_health_description = {\n    \"EDAnonymous\": \"An eating disorder is a mental disorder defined by abnormal eating behaviors that negatively affect a person's physical or mental health. Types of eating disorders include binge eating disorder, where the patient eats a large amount in a short period of time; anorexia nervosa, where the person has an intense fear of gaining weight and restricts food or overexercises to manage this fear; bulimia nervosa, where individuals eat a large quantity (binging) then try to rid themselves of the food (purging); pica, where the patient eats non-food items; rumination syndrome, where the patient regurgitates undigested or minimally digested food; avoidant/restrictive food intake disorder (ARFID), where people have a reduced or selective food intake due to some psychological reasons; and a group of other specified feeding or eating disorders. Anxiety disorders, depression and substance abuse are common among people with eating disorders. These disorders do not include obesity.\",\n    \"addiction\": \"Addiction is generally a neuropsychological symptom defining pervasive and intense urge to engage in maladaptive behaviors providing immediate sensory rewards (e.g. consuming drugs, excessively gambling), despite their harmful consequences. Dependence is generally an addiction that can involve withdrawal issues. Addictive disorder is a category of mental disorders defining important intensities of addictions or dependences, which induce functional disabilities.\",\n    \"adhd\": \"Attention deficit hyperactivity disorder (ADHD) is a neurodevelopmental disorder characterised by excessive amounts of inattention, hyperactivity, and impulsivity that are pervasive, impairing in multiple contexts, and otherwise age-inappropriate.\",\n    \"alcoholism\": \"Alcoholism is, broadly, any drinking of alcohol that results in significant mental or physical health problems. Because there is disagreement on the definition of the word alcoholism, it is not a recognized diagnostic entity, and the use of alcoholism terminology is discouraged due to its heavily stigmatized connotations. Predominant diagnostic classifications are alcohol use disorder (DSM-5) or alcohol dependence (ICD-11).\",\n    \"anxiety\": \"Anxiety is an emotion which is characterized by an unpleasant state of inner turmoil and includes feelings of dread over anticipated events. Anxiety is different than fear in that the former is defined as the anticipation of a future threat whereas the latter is defined as the emotional response to a real threat. It is often accompanied by nervous behavior such as pacing back and forth, somatic complaints, and rumination.\",\n    \"autism\": \"The autism spectrum, often referred to as just autism, autism spectrum disorder (ASD) or sometimes autism spectrum condition (ASC), identifies a loosely defined cluster of neurodevelopmental disorders characterized by challenges in social interaction, verbal and nonverbal communication, and often repetitive behaviors and restricted interests. Other common features include unusual responses to sensory stimuli and a preference for sameness or unusual adherence to routines.\",\n    \"bipolarreddit\": \"Bipolar disorder, previously known as manic depression, is a mental disorder characterized by periods of depression and periods of abnormally elevated mood that each last from days to weeks. If the elevated mood is severe or associated with psychosis, it is called mania; if it is less severe, it is called hypomania. During mania, an individual behaves or feels abnormally energetic, happy or irritable, and they often make impulsive decisions with little regard for the consequences. There is usually also a reduced need for sleep during manic phases. During periods of depression, the individual may experience crying and have a negative outlook on life and poor eye contact with others. The risk of suicide is high. Other mental health issues, such as anxiety disorders and substance use disorders, are commonly associated with bipolar disorder.\",\n    \"bpd\": \"Borderline personality disorder (BPD), also known as emotionally unstable personality disorder (EUPD), is a personality disorder characterized by a long-term pattern of intense and unstable interpersonal relationships, distorted sense of self, and strong emotional reactions. Those affected often engage in self-harm and other dangerous behaviors, often due to their difficulty with returning their emotional level to a healthy or normal baseline. They may also struggle with a feeling of emptiness, fear of abandonment, and detachment from reality.\",\n    \"depression\": \"Depression is a mental state of low mood and aversion to activity. It affects more than 280 million people of all ages (about 3.5% of the global population). Depression affects a person's thoughts, behavior, feelings, and sense of well-being. Depressed people often experience loss of motivation or interest in, or reduced pleasure or joy from, experiences that would normally bring them pleasure or joy. Depressed mood is a symptom of some mood disorders such as major depressive disorder and dysthymia; it is a normal temporary reaction to life events, such as the loss of a loved one; and it is also a symptom of some physical diseases and a side effect of some drugs and medical treatments. It may feature sadness, difficulty in thinking and concentration and a significant increase or decrease in appetite and time spent sleeping. People experiencing depression may have feelings of dejection or hopelessness and may experience suicidal thoughts.\",\n    \"healthanxiety\": \"Hypochondriasis or hypochondria is a condition in which a person is excessively and unduly worried about having a serious illness. Hypochondria is an old concept whose meaning has repeatedly changed over its lifespan. It has been claimed that this debilitating condition results from an inaccurate perception of the condition of body or mind despite the absence of an actual medical diagnosis. An individual with hypochondriasis is known as a hypochondriac. Hypochondriacs become unduly alarmed about any physical or psychological symptoms they detect, no matter how minor the symptom may be, and are convinced that they have, or are about to be diagnosed with, a serious illness.\",\n    \"lonely\": \"Loneliness is an unpleasant emotional response to perceived isolation. Loneliness is also described as social pain – a psychological mechanism which motivates individuals to seek social connections. It is often associated with a perceived lack of connection and intimacy. Loneliness overlaps and yet is distinct from solitude. Solitude is simply the state of being apart from others; not everyone who experiences solitude feels lonely. As a subjective emotion, loneliness can be felt even when a person is surrounded by other people. Hence, there is a distinction between being alone and feeling lonely. Loneliness can be short term (state loneliness) or long term (chronic loneliness). In either case, it can be intense and painful.\",\n    \"ptsd\": \"Post-traumatic stress disorder (PTSD) is a mental and behavioral disorder that can develop because of exposure to a traumatic event, such as sexual assault, warfare, traffic collisions, child abuse, domestic violence, or other threats on a person's life. Symptoms may include disturbing thoughts, feelings, or dreams related to the events, mental or physical distress to trauma-related cues, attempts to avoid trauma-related cues, alterations in the way a person thinks and feels, and an increase in the fight-or-flight response. These symptoms last for more than a month after the event. Young children are less likely to show distress but instead may express their memories through play. A person with PTSD is at a higher risk of suicide and intentional self-harm.\",\n    \"schizophrenia\": \"Schizophrenia is a mental disorder characterized by continuous or relapsing episodes of psychosis. Major symptoms include hallucinations (typically hearing voices), delusions, and disorganized thinking. Other symptoms include social withdrawal, decreased emotional expression, and apathy. Symptoms typically develop gradually, begin during young adulthood, and in many cases never become resolved. There is no objective diagnostic test; diagnosis is based on observed behavior, a psychiatric history that includes the person's reported experiences, and reports of others familiar with the person. To be diagnosed with schizophrenia, symptoms and functional impairment need to be present for six months (DSM-5) or one month (ICD-11). Many people with schizophrenia have other mental disorders, especially substance use disorders, depressive disorders, anxiety disorders, and obsessive–compulsive disorder.\",\n    \"socialanxiety\": \"Social anxiety is the anxiety and fear specifically linked to being in social settings (i.e., interacting with others). Some categories of disorders associated with social anxiety include anxiety disorders, mood disorders, autism spectrum disorders, eating disorders, and substance use disorders. Individuals with higher levels of social anxiety often avert their gazes, show fewer facial expressions, and show difficulty with initiating and maintaining a conversation. Social anxiety commonly manifests itself in the teenage years and can be persistent throughout life, however, people who experience problems in their daily functioning for an extended period of time can develop social anxiety disorder. Trait social anxiety, the stable tendency to experience this anxiety, can be distinguished from state anxiety, the momentary response to a particular social stimulus. Half of the individuals with any social fears meet the criteria for social anxiety disorder. Age, culture, and gender impact the severity of this disorder.\",\n    \"suicidewatch\": \"Suicide is the act of intentionally causing one's own death. Mental disorders (including depression, bipolar disorder, schizophrenia, personality disorders, anxiety disorders), physical disorders (such as chronic fatigue syndrome), and substance abuse (including alcoholism and the use of and withdrawal from benzodiazepines) are risk factors. Some suicides are impulsive acts due to stress (such as from financial or academic difficulties), relationship problems (such as breakups or divorces), or harassment and bullying. Those who have previously attempted suicide are at a higher risk for future attempts. Effective suicide prevention efforts include limiting access to methods of suicide such as firearms, drugs, and poisons; treating mental disorders and substance abuse; careful media reporting about suicide; and improving economic conditions.\",\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for k, v in mental_health_description.items():\n#     print(k, len(v.split(' ')))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mental_health_sentence_embedding = {k: sentence_model.encode(s) for k, s in mental_health_description.items()}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/reddit-mental-health-v2/mental_health_sentence_embedding.pickle', 'rb') as handle:\n    mental_health_sentence_embedding = pickle.load(handle)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ### preprocessing\n# x_train, x_train_swear_words, x_train_token_num, x_train_emoji_num, x_train_upper_count, x_train_unique_words_num, x_train_characters_num = zip(*train_df[\"post\"].apply(lambda x: content_preprocessing(x)))\n# # x_train_swear_words = np.array(x_train_swear_words, dtype=np.long).reshape(-1, 1)\n# # x_train_token_num = np.array(x_train_token_num, dtype=np.long).reshape(-1, 1)\n# # x_train_emoji_num = np.array(x_train_emoji_num, dtype=np.long).reshape(-1, 1)\n# # x_train_upper_count = np.array(x_train_upper_count, dtype=np.long).reshape(-1, 1)\n# # x_train_unique_words_num = np.array(x_train_unique_words_num, dtype=np.long).reshape(-1, 1)\n# # x_train_characters_num = np.array(x_train_characters_num, dtype=np.long).reshape(-1, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x_test, x_test_swear_words, x_test_token_num, x_test_emoji_num, x_test_upper_count, x_test_unique_words_num, x_test_characters_num  = zip(*test_df[\"Text\"].apply(lambda x: content_preprocessing(x)))\n# x_test_swear_words = np.array(x_test_swear_words).reshape(-1, 1)\n# x_test_token_num = np.array(x_test_token_num, dtype=np.long).reshape(-1, 1)\n# x_test_emoji_num = np.array(x_test_emoji_num, dtype=np.long).reshape(-1, 1)\n# x_test_upper_count = np.array(x_test_upper_count, dtype=np.long).reshape(-1, 1)\n# x_test_unique_words_num = np.array(x_test_unique_words_num, dtype=np.long).reshape(-1, 1)\n# x_test_characters_num = np.array(x_test_characters_num, dtype=np.long).reshape(-1, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = train_df['label'].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_df\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # generate word2vec embedding\n# crawl_matrix, oov = build_matrix(tokenizer.word_index, CRAWL_EMBEDDING_PATH)\n# # glove_matrix , oov2 = build_matrix(tokenizer.word_index, GLOVE_EMBEDDING_PATH)\n# # embedding_matrix = (crawl_matrix+glove_matrix)/2\n# # embedding_matrix = np.concatenate((crawl_matrix, glove_matrix), axis=-1)\ncrawl_matrix = np.load(\"../input/reddit-mental-health-v2/crawl_matrix_reddit_mental_health_cut.npy\")\n\n# with open('crawl_matrix_reddit_mental_health_cut_v4.npy', 'wb') as f:\n#     np.save(f, crawl_matrix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # shuffle the data\n# permu_idx = np.random.permutation(len(x_train))\n# x_train = x_train[permu_idx]\n# y_train = y_train[permu_idx]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test_tensor = torch.tensor(x_test, dtype=torch.long)#.cuda()\nx_test_roberta_tensor = torch.tensor(test_roberta, dtype=torch.float)#.cuda()\ntest_data = torch.utils.data.TensorDataset(x_test_tensor, x_test_roberta_tensor)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n\ndel x_test_tensor, x_test_roberta_tensor, test_data\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import f1_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def loss_fn(outputs, targets):\n#     return torch.nn.BCEWithLogitsLoss()(outputs, targets)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def stratified_group_k_fold(X, y, groups, k, seed=None):\n#     labels_num = np.max(y) + 1\n#     y_counts_per_group = defaultdict(lambda: np.zeros(labels_num))\n#     y_distr = Counter()\n#     for label, g in zip(y, groups):\n#         y_counts_per_group[g][label] += 1\n#         y_distr[label] += 1\n\n#     y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num))\n#     groups_per_fold = defaultdict(set)\n\n#     def eval_y_counts_per_fold(y_counts, fold):\n#         y_counts_per_fold[fold] += y_counts\n#         std_per_label = []\n#         for label in range(labels_num):\n#             label_std = np.std([y_counts_per_fold[i][label] / y_distr[label] for i in range(k)])\n#             std_per_label.append(label_std)\n#         y_counts_per_fold[fold] -= y_counts\n#         return np.mean(std_per_label)\n    \n#     groups_and_y_counts = list(y_counts_per_group.items())\n#     random.Random(seed).shuffle(groups_and_y_counts)\n\n#     for g, y_counts in sorted(groups_and_y_counts, key=lambda x: -np.std(x[1])):\n#         best_fold = None\n#         min_eval = None\n#         for i in range(k):\n#             fold_eval = eval_y_counts_per_fold(y_counts, i)\n#             if min_eval is None or fold_eval < min_eval:\n#                 min_eval = fold_eval\n#                 best_fold = i\n#         y_counts_per_fold[best_fold] += y_counts\n#         groups_per_fold[best_fold].add(g)\n\n#     all_groups = set(groups)\n#     for i in range(k):\n#         train_groups = all_groups - groups_per_fold[i]\n#         test_groups = groups_per_fold[i]\n\n#         train_indices = [i for i, g in enumerate(groups) if g in train_groups]\n#         test_indices = [i for i, g in enumerate(groups) if g in test_groups]\n\n#         yield train_indices, test_indices","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mhe_depression_np = mental_health_sentence_embedding['depression'].reshape(1, -1)\nmhe_autism_np = mental_health_sentence_embedding['autism'].reshape(1, -1)\nmhe_ptsd_np = mental_health_sentence_embedding['ptsd'].reshape(1, -1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mhe_EDAnonymous_np = mental_health_sentence_embedding['EDAnonymous'].reshape(1, -1)\nmhe_addiction_np = mental_health_sentence_embedding['addiction'].reshape(1, -1)\nmhe_adhd_np = mental_health_sentence_embedding['adhd'].reshape(1, -1)\nmhe_alcoholism_np = mental_health_sentence_embedding['alcoholism'].reshape(1, -1)\nmhe_anxiety_np = mental_health_sentence_embedding['anxiety'].reshape(1, -1)\nmhe_bipolarreddit_np = mental_health_sentence_embedding['bipolarreddit'].reshape(1, -1)\nmhe_bpd_np = mental_health_sentence_embedding['bpd'].reshape(1, -1)\nmhe_healthanxiety_np = mental_health_sentence_embedding['healthanxiety'].reshape(1, -1)\nmhe_lonely_np = mental_health_sentence_embedding['lonely'].reshape(1, -1)\nmhe_schizophrenia_np = mental_health_sentence_embedding['schizophrenia'].reshape(1, -1)\nmhe_socialanxiety_np = mental_health_sentence_embedding['socialanxiety'].reshape(1, -1)\nmhe_suicidewatch_np = mental_health_sentence_embedding['suicidewatch'].reshape(1, -1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # oof = np.zeros(len(x_train)*NUM_MODEL)\n# final_test = list()\n# val_f1_score = list()\n\n# for index in range(NUM_MODEL):\n    \n#     print(\"model: {}\".format(index))\n    \n#     x_train_fold, x_val, y_train_fold, y_val = train_test_split(x_train, y_train, test_size=0.2)\n\n#     x_train_fold = torch.tensor(x_train_fold, dtype=torch.long).cuda()\n#     x_val = torch.tensor(x_val, dtype=torch.long).cuda()\n#     y_train_fold = torch.tensor(y_train_fold, dtype=torch.float).cuda()\n#     y_val = torch.tensor(y_val, dtype=torch.float).cuda()\n\n#     train_data = torch.utils.data.TensorDataset(x_train_fold, y_train_fold)\n#     val_data = torch.utils.data.TensorDataset(x_val, y_val)\n\n#     train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n#     val_loader = torch.utils.data.DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n   \n#     del x_train_fold, x_val, y_train_fold, train_data, val_data\n#     gc.collect()\n\n#     net = NeuralNet(crawl_matrix, 256, 1)\n#     net.cuda()\n#     loss_fn = torch.nn.BCELoss(reduction='mean')\n#     # loss_fn = nn.CrossEntropyLoss()\n#     # optimizer = torch.optim.Adam(net.parameters(), lr=0.002)\n#     optimizer = torch.optim.AdamW(params =  net.parameters(), lr=0.002, weight_decay=1e-7)\n\n#     test_checkpoint = list()\n#     loss_checkpoint = list()\n#     val_f1_epoch = list()\n    \n#     for epoch in range(EPOCHS): \n        \n#         start_time = time.time()\n\n#         avg_loss = 0.0\n        \n#         net.train()\n#         for i, data in enumerate(train_loader):\n            \n#             # get the inputs\n#             inputs, labels = data\n            \n#             mhe_depression = np.tile(mhe_depression_np,(inputs.shape[0],1)) # 512,1024\n#             mhe_autism = np.tile(mhe_autism_np,(inputs.shape[0],1)) # 512,1024\n#             mhe_ptsd = np.tile(mhe_ptsd_np,(inputs.shape[0],1)) # 512,1024 \n#             mhe_EDAnonymous = np.tile(mhe_EDAnonymous_np,(inputs.shape[0],1)) # 512,1024\n#             mhe_addiction = np.tile(mhe_addiction_np,(inputs.shape[0],1)) # 512,1024\n#             mhe_adhd = np.tile(mhe_adhd_np,(inputs.shape[0],1)) # 512,1024             \n#             mhe_alcoholism = np.tile(mhe_alcoholism_np,(inputs.shape[0],1)) # 512,1024\n#             mhe_anxiety = np.tile(mhe_anxiety_np,(inputs.shape[0],1)) # 512,1024\n#             mhe_bipolarreddit = np.tile(mhe_bipolarreddit_np,(inputs.shape[0],1)) # 512,1024  \n#             mhe_bpd = np.tile(mhe_bpd_np,(inputs.shape[0],1)) # 512,1024\n#             mhe_healthanxiety = np.tile(mhe_healthanxiety_np,(inputs.shape[0],1)) # 512,1024\n#             mhe_lonely = np.tile(mhe_lonely_np,(inputs.shape[0],1)) # 512,1024             \n#             mhe_schizophrenia = np.tile(mhe_schizophrenia_np,(inputs.shape[0],1)) # 512,1024\n#             mhe_socialanxiety = np.tile(mhe_socialanxiety_np,(inputs.shape[0],1)) # 512,1024\n#             mhe_suicidewatch = np.tile(mhe_suicidewatch_np,(inputs.shape[0],1)) # 512,1024            \n            \n#             mhe_depression = torch.tensor(mhe_depression, dtype=torch.float).cuda()\n#             mhe_autism = torch.tensor(mhe_autism, dtype=torch.float).cuda()\n#             mhe_ptsd = torch.tensor(mhe_ptsd, dtype=torch.float).cuda()\n#             mhe_EDAnonymous = torch.tensor(mhe_EDAnonymous, dtype=torch.float).cuda()\n#             mhe_addiction = torch.tensor(mhe_addiction, dtype=torch.float).cuda()\n#             mhe_adhd = torch.tensor(mhe_adhd, dtype=torch.float).cuda()\n#             mhe_alcoholism = torch.tensor(mhe_alcoholism, dtype=torch.float).cuda()\n#             mhe_anxiety = torch.tensor(mhe_anxiety, dtype=torch.float).cuda()\n#             mhe_bipolarreddit = torch.tensor(mhe_bipolarreddit, dtype=torch.float).cuda()   \n#             mhe_bpd = torch.tensor(mhe_bpd, dtype=torch.float).cuda()\n#             mhe_healthanxiety = torch.tensor(mhe_healthanxiety, dtype=torch.float).cuda()\n#             mhe_lonely = torch.tensor(mhe_lonely, dtype=torch.float).cuda()\n#             mhe_schizophrenia = torch.tensor(mhe_schizophrenia, dtype=torch.float).cuda()\n#             mhe_socialanxiety = torch.tensor(mhe_socialanxiety, dtype=torch.float).cuda()\n#             mhe_suicidewatch = torch.tensor(mhe_suicidewatch, dtype=torch.float).cuda()\n  \n#             mhe_total = torch.stack([mhe_depression, \n#                                      mhe_autism, \n#                                      mhe_ptsd,\n#                                      mhe_EDAnonymous,\n#                                      mhe_addiction,\n#                                      mhe_adhd,\n#                                      mhe_alcoholism,\n#                                      mhe_anxiety,\n#                                      mhe_bipolarreddit,\n#                                      mhe_bpd,\n#                                      mhe_healthanxiety,\n#                                      mhe_lonely,\n#                                      mhe_schizophrenia,\n#                                      mhe_socialanxiety,\n#                                      mhe_suicidewatch\n#                                     ], dim=1)\n#             # mhe_depression = torch.unsqueeze(mhe_depression, 1) # 512,1,1024\n            \n#             ## forward + backward + optimize\n#             pred1 = net(inputs, mhe_total)\n            \n#             loss1 = loss_fn(pred1, labels.unsqueeze(1))\n#             # loss2 = loss_fn(pred2,label2)\n#             # loss = loss1*loss_weight+loss2\n#             # loss = loss1\n           \n#             # zero the parameter gradients\n#             optimizer.zero_grad()\n\n#             loss1.backward()\n#             optimizer.step()\n\n#             avg_loss += loss1.item()\n\n#         net.eval()\n        \n#         valid_preds = np.zeros((len(y_val),))\n#         true_label = np.zeros((len(y_val),))\n\n#         avg_val_loss = 0.0\n\n#         for j, data in enumerate(val_loader):\n            \n#             # get the inputs\n#             inputs, labels = data\n            \n#             mhe_depression = np.tile(mhe_depression_np,(inputs.shape[0],1)) # 512,1024\n#             mhe_autism = np.tile(mhe_autism_np,(inputs.shape[0],1)) # 512,1024\n#             mhe_ptsd = np.tile(mhe_ptsd_np,(inputs.shape[0],1)) # 512,1024 \n#             mhe_EDAnonymous = np.tile(mhe_EDAnonymous_np,(inputs.shape[0],1)) # 512,1024\n#             mhe_addiction = np.tile(mhe_addiction_np,(inputs.shape[0],1)) # 512,1024\n#             mhe_adhd = np.tile(mhe_adhd_np,(inputs.shape[0],1)) # 512,1024             \n#             mhe_alcoholism = np.tile(mhe_alcoholism_np,(inputs.shape[0],1)) # 512,1024\n#             mhe_anxiety = np.tile(mhe_anxiety_np,(inputs.shape[0],1)) # 512,1024\n#             mhe_bipolarreddit = np.tile(mhe_bipolarreddit_np,(inputs.shape[0],1)) # 512,1024  \n#             mhe_bpd = np.tile(mhe_bpd_np,(inputs.shape[0],1)) # 512,1024\n#             mhe_healthanxiety = np.tile(mhe_healthanxiety_np,(inputs.shape[0],1)) # 512,1024\n#             mhe_lonely = np.tile(mhe_lonely_np,(inputs.shape[0],1)) # 512,1024             \n#             mhe_schizophrenia = np.tile(mhe_schizophrenia_np,(inputs.shape[0],1)) # 512,1024\n#             mhe_socialanxiety = np.tile(mhe_socialanxiety_np,(inputs.shape[0],1)) # 512,1024\n#             mhe_suicidewatch = np.tile(mhe_suicidewatch_np,(inputs.shape[0],1)) # 512,1024            \n            \n#             mhe_depression = torch.tensor(mhe_depression, dtype=torch.float).cuda()\n#             mhe_autism = torch.tensor(mhe_autism, dtype=torch.float).cuda()\n#             mhe_ptsd = torch.tensor(mhe_ptsd, dtype=torch.float).cuda()\n#             mhe_EDAnonymous = torch.tensor(mhe_EDAnonymous, dtype=torch.float).cuda()\n#             mhe_addiction = torch.tensor(mhe_addiction, dtype=torch.float).cuda()\n#             mhe_adhd = torch.tensor(mhe_adhd, dtype=torch.float).cuda()\n#             mhe_alcoholism = torch.tensor(mhe_alcoholism, dtype=torch.float).cuda()\n#             mhe_anxiety = torch.tensor(mhe_anxiety, dtype=torch.float).cuda()\n#             mhe_bipolarreddit = torch.tensor(mhe_bipolarreddit, dtype=torch.float).cuda()   \n#             mhe_bpd = torch.tensor(mhe_bpd, dtype=torch.float).cuda()\n#             mhe_healthanxiety = torch.tensor(mhe_healthanxiety, dtype=torch.float).cuda()\n#             mhe_lonely = torch.tensor(mhe_lonely, dtype=torch.float).cuda()\n#             mhe_schizophrenia = torch.tensor(mhe_schizophrenia, dtype=torch.float).cuda()\n#             mhe_socialanxiety = torch.tensor(mhe_socialanxiety, dtype=torch.float).cuda()\n#             mhe_suicidewatch = torch.tensor(mhe_suicidewatch, dtype=torch.float).cuda()\n  \n#             mhe_total = torch.stack([mhe_depression, \n#                                      mhe_autism, \n#                                      mhe_ptsd,\n#                                      mhe_EDAnonymous,\n#                                      mhe_addiction,\n#                                      mhe_adhd,\n#                                      mhe_alcoholism,\n#                                      mhe_anxiety,\n#                                      mhe_bipolarreddit,\n#                                      mhe_bpd,\n#                                      mhe_healthanxiety,\n#                                      mhe_lonely,\n#                                      mhe_schizophrenia,\n#                                      mhe_socialanxiety,\n#                                      mhe_suicidewatch\n#                                     ], dim=1)\n#             # mhe_depression = torch.unsqueeze(mhe_depression, 1) # 512,1,1024\n            \n#             ## forward + backward + optimize\n#             pred1 = net(inputs, mhe_total)\n            \n#             loss1_val = loss_fn(pred1, labels.unsqueeze(1))\n\n#             avg_val_loss += loss1_val.item()\n#             # (torch.argmax(y_pred, 1) == torch.argmax(y_test, 1)).float().mean()\n            \n#             valid_preds[j * BATCH_SIZE:(j+1) * BATCH_SIZE] = (pred1.squeeze().cpu().detach().numpy()>=0.5).astype(float)\n#             # true_label[j * BATCH_SIZE:(j+1) * BATCH_SIZE]  = torch.argmax(labels, 1).cpu().detach().numpy()\n#             true_label[j * BATCH_SIZE:(j+1) * BATCH_SIZE]  = labels.cpu().detach().numpy()\n            \n#         elapsed_time = time.time() - start_time \n\n#         print('Epoch {}/{} \\t loss={:.4f}\\t val_loss={:.4f} \\t val_f1_score={:.4f} \\t time={:.2f}s'.format(\n#                         epoch+1, EPOCHS, avg_loss/len(train_loader),avg_val_loss/len(val_loader), f1_score(true_label, valid_preds, average='micro'), elapsed_time))\n#         val_f1_epoch.append(f1_score(true_label, valid_preds, average='micro'))\n        \n#         ## inference\n#         result = list()\n#         with torch.no_grad():\n#             for (x_batch,) in test_loader:\n                \n#                 mhe_depression = np.tile(mhe_depression_np,(x_batch.shape[0],1)) # 512,1024\n#                 mhe_autism = np.tile(mhe_autism_np,(x_batch.shape[0],1)) # 512,1024\n#                 mhe_ptsd = np.tile(mhe_ptsd_np,(x_batch.shape[0],1)) # 512,1024 \n#                 mhe_EDAnonymous = np.tile(mhe_EDAnonymous_np,(x_batch.shape[0],1)) # 512,1024\n#                 mhe_addiction = np.tile(mhe_addiction_np,(x_batch.shape[0],1)) # 512,1024\n#                 mhe_adhd = np.tile(mhe_adhd_np,(x_batch.shape[0],1)) # 512,1024             \n#                 mhe_alcoholism = np.tile(mhe_alcoholism_np,(x_batch.shape[0],1)) # 512,1024\n#                 mhe_anxiety = np.tile(mhe_anxiety_np,(x_batch.shape[0],1)) # 512,1024\n#                 mhe_bipolarreddit = np.tile(mhe_bipolarreddit_np,(x_batch.shape[0],1)) # 512,1024  \n#                 mhe_bpd = np.tile(mhe_bpd_np,(x_batch.shape[0],1)) # 512,1024\n#                 mhe_healthanxiety = np.tile(mhe_healthanxiety_np,(x_batch.shape[0],1)) # 512,1024\n#                 mhe_lonely = np.tile(mhe_lonely_np,(x_batch.shape[0],1)) # 512,1024             \n#                 mhe_schizophrenia = np.tile(mhe_schizophrenia_np,(x_batch.shape[0],1)) # 512,1024\n#                 mhe_socialanxiety = np.tile(mhe_socialanxiety_np,(x_batch.shape[0],1)) # 512,1024\n#                 mhe_suicidewatch = np.tile(mhe_suicidewatch_np,(x_batch.shape[0],1)) # 512,1024            \n\n#                 mhe_depression = torch.tensor(mhe_depression, dtype=torch.float).cuda()\n#                 mhe_autism = torch.tensor(mhe_autism, dtype=torch.float).cuda()\n#                 mhe_ptsd = torch.tensor(mhe_ptsd, dtype=torch.float).cuda()\n#                 mhe_EDAnonymous = torch.tensor(mhe_EDAnonymous, dtype=torch.float).cuda()\n#                 mhe_addiction = torch.tensor(mhe_addiction, dtype=torch.float).cuda()\n#                 mhe_adhd = torch.tensor(mhe_adhd, dtype=torch.float).cuda()\n#                 mhe_alcoholism = torch.tensor(mhe_alcoholism, dtype=torch.float).cuda()\n#                 mhe_anxiety = torch.tensor(mhe_anxiety, dtype=torch.float).cuda()\n#                 mhe_bipolarreddit = torch.tensor(mhe_bipolarreddit, dtype=torch.float).cuda()   \n#                 mhe_bpd = torch.tensor(mhe_bpd, dtype=torch.float).cuda()\n#                 mhe_healthanxiety = torch.tensor(mhe_healthanxiety, dtype=torch.float).cuda()\n#                 mhe_lonely = torch.tensor(mhe_lonely, dtype=torch.float).cuda()\n#                 mhe_schizophrenia = torch.tensor(mhe_schizophrenia, dtype=torch.float).cuda()\n#                 mhe_socialanxiety = torch.tensor(mhe_socialanxiety, dtype=torch.float).cuda()\n#                 mhe_suicidewatch = torch.tensor(mhe_suicidewatch, dtype=torch.float).cuda()\n\n#                 mhe_total = torch.stack([mhe_depression, \n#                                          mhe_autism, \n#                                          mhe_ptsd,\n#                                          mhe_EDAnonymous,\n#                                          mhe_addiction,\n#                                          mhe_adhd,\n#                                          mhe_alcoholism,\n#                                          mhe_anxiety,\n#                                          mhe_bipolarreddit,\n#                                          mhe_bpd,\n#                                          mhe_healthanxiety,\n#                                          mhe_lonely,\n#                                          mhe_schizophrenia,\n#                                          mhe_socialanxiety,\n#                                          mhe_suicidewatch\n#                                         ], dim=1)\n#                 y_pred = net(x_batch, mhe_total)\n#                 y_pred = y_pred.cpu().detach().numpy()\n#                 result.extend(y_pred)\n\n#         test_checkpoint.append(result)\n#         loss_checkpoint.append(avg_val_loss)\n        \n        \n#     final_test.append(test_checkpoint[np.argmin(loss_checkpoint)])\n#     val_f1_score.append(val_f1_epoch[np.argmin(loss_checkpoint)])\n#     with open(\"final_test_{}\".format(index), \"wb\") as fp:\n#         pickle.dump(final_test, fp)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# oof = np.zeros(len(x_train)*NUM_MODEL)\nfinal_test = list()\nval_f1_score = list()\n\nNFOLDS = 5\n# folds = KFold(n_splits=NFOLDS, shuffle=True, random_state=SEED)\n\n# for fold_, (trn_idx, val_idx) in enumerate(folds.split(x_train)):\n\nskf = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=SEED)\n\nfor fold_, (trn_idx, val_idx) in enumerate(skf.split(x_train, y_train)):\n        \n    print(\"Fold: {}/{}\".format(fold_ + 1, NFOLDS))\n     \n#     x_train_fold = x_train[trn_idx]\n#     x_val = x_train[val_idx]\n#     y_train_fold = y_train[trn_idx]\n#     y_val = y_train[val_idx]\n#     x_train_roberta = train_roberta[trn_idx]\n#     x_val_roberta = train_roberta[val_idx]\n    \n#     x_train_fold = torch.tensor(x_train_fold, dtype=torch.long)#.cuda()\n#     x_val = torch.tensor(x_val, dtype=torch.long)#.cuda()\n#     y_train_fold = torch.tensor(y_train_fold, dtype=torch.float)#.cuda()\n#     y_val = torch.tensor(y_val, dtype=torch.float)#.cuda()\n#     x_train_roberta = torch.tensor(x_train_roberta, dtype=torch.float)#.cuda()\n#     x_val_roberta = torch.tensor(x_val_roberta, dtype=torch.float)#.cuda()\n#     x_train_fold = torch.tensor(x_train[trn_idx], dtype=torch.long)#.cuda()\n#     x_val = torch.tensor(x_train[val_idx], dtype=torch.long)#.cuda()\n#     y_train_fold = torch.tensor(y_train[trn_idx], dtype=torch.float)#.cuda()\n#     y_val = torch.tensor(y_train[val_idx], dtype=torch.float)#.cuda()\n#     x_train_roberta = torch.tensor(train_roberta[trn_idx], dtype=torch.float)#.cuda()\n#     x_val_roberta = torch.tensor(train_roberta[val_idx], dtype=torch.float)#.cuda()\n    \n#     train_data = torch.utils.data.TensorDataset(x_train_fold, x_train_roberta, y_train_fold)\n#     val_data = torch.utils.data.TensorDataset(x_val, x_val_roberta, y_val)\n    train_data = torch.utils.data.TensorDataset(torch.tensor(x_train[trn_idx], dtype=torch.long), torch.tensor(train_roberta[trn_idx], dtype=torch.float), torch.tensor(y_train[trn_idx], dtype=torch.float))\n    val_data = torch.utils.data.TensorDataset(torch.tensor(x_train[val_idx], dtype=torch.long), torch.tensor(train_roberta[val_idx], dtype=torch.float), torch.tensor(y_train[val_idx], dtype=torch.float))\n\n    train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n    val_loader = torch.utils.data.DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n\n#     del x_train_fold, x_val, y_train_fold, train_data, val_data, x_train_roberta, x_val_roberta\n#     gc.collect()\n\n\n    net = NeuralNet(crawl_matrix, 256, 1)\n    net.cuda()\n    loss_fn = torch.nn.BCELoss(reduction='mean')\n    # loss_fn = nn.CrossEntropyLoss()\n    # optimizer = torch.optim.Adam(net.parameters(), lr=0.002)\n    optimizer = torch.optim.AdamW(params =  net.parameters(), lr=0.002, weight_decay=1e-7)\n\n    test_checkpoint = list()\n    loss_checkpoint = list()\n    val_f1_epoch = list()\n    \n    for epoch in range(EPOCHS): \n        \n        start_time = time.time()\n\n        avg_loss = 0.0\n        \n        net.train()\n        for i, data in enumerate(train_loader):\n            \n            # get the inputs\n            inputs, inputs_roberta, labels = data\n            inputs, inputs_roberta, labels = inputs.cuda(), inputs_roberta.cuda(), labels.cuda()\n            \n            mhe_depression = np.tile(mhe_depression_np,(inputs.shape[0],1)) # 512,1024\n            mhe_autism = np.tile(mhe_autism_np,(inputs.shape[0],1)) # 512,1024\n            mhe_ptsd = np.tile(mhe_ptsd_np,(inputs.shape[0],1)) # 512,1024 \n            mhe_EDAnonymous = np.tile(mhe_EDAnonymous_np,(inputs.shape[0],1)) # 512,1024\n            mhe_addiction = np.tile(mhe_addiction_np,(inputs.shape[0],1)) # 512,1024\n            mhe_adhd = np.tile(mhe_adhd_np,(inputs.shape[0],1)) # 512,1024             \n            mhe_alcoholism = np.tile(mhe_alcoholism_np,(inputs.shape[0],1)) # 512,1024\n            mhe_anxiety = np.tile(mhe_anxiety_np,(inputs.shape[0],1)) # 512,1024\n            mhe_bipolarreddit = np.tile(mhe_bipolarreddit_np,(inputs.shape[0],1)) # 512,1024  \n            mhe_bpd = np.tile(mhe_bpd_np,(inputs.shape[0],1)) # 512,1024\n            mhe_healthanxiety = np.tile(mhe_healthanxiety_np,(inputs.shape[0],1)) # 512,1024\n            mhe_lonely = np.tile(mhe_lonely_np,(inputs.shape[0],1)) # 512,1024             \n            mhe_schizophrenia = np.tile(mhe_schizophrenia_np,(inputs.shape[0],1)) # 512,1024\n            mhe_socialanxiety = np.tile(mhe_socialanxiety_np,(inputs.shape[0],1)) # 512,1024\n            mhe_suicidewatch = np.tile(mhe_suicidewatch_np,(inputs.shape[0],1)) # 512,1024            \n            \n            mhe_depression = torch.tensor(mhe_depression, dtype=torch.float).cuda()\n            mhe_autism = torch.tensor(mhe_autism, dtype=torch.float).cuda()\n            mhe_ptsd = torch.tensor(mhe_ptsd, dtype=torch.float).cuda()\n            mhe_EDAnonymous = torch.tensor(mhe_EDAnonymous, dtype=torch.float).cuda()\n            mhe_addiction = torch.tensor(mhe_addiction, dtype=torch.float).cuda()\n            mhe_adhd = torch.tensor(mhe_adhd, dtype=torch.float).cuda()\n            mhe_alcoholism = torch.tensor(mhe_alcoholism, dtype=torch.float).cuda()\n            mhe_anxiety = torch.tensor(mhe_anxiety, dtype=torch.float).cuda()\n            mhe_bipolarreddit = torch.tensor(mhe_bipolarreddit, dtype=torch.float).cuda()   \n            mhe_bpd = torch.tensor(mhe_bpd, dtype=torch.float).cuda()\n            mhe_healthanxiety = torch.tensor(mhe_healthanxiety, dtype=torch.float).cuda()\n            mhe_lonely = torch.tensor(mhe_lonely, dtype=torch.float).cuda()\n            mhe_schizophrenia = torch.tensor(mhe_schizophrenia, dtype=torch.float).cuda()\n            mhe_socialanxiety = torch.tensor(mhe_socialanxiety, dtype=torch.float).cuda()\n            mhe_suicidewatch = torch.tensor(mhe_suicidewatch, dtype=torch.float).cuda()\n  \n            mhe_total = torch.stack([mhe_depression, \n                                     mhe_autism, \n                                     mhe_ptsd,\n                                     mhe_EDAnonymous,\n                                     mhe_addiction,\n                                     mhe_adhd,\n                                     mhe_alcoholism,\n                                     mhe_anxiety,\n                                     mhe_bipolarreddit,\n                                     mhe_bpd,\n                                     mhe_healthanxiety,\n                                     mhe_lonely,\n                                     mhe_schizophrenia,\n                                     mhe_socialanxiety,\n                                     mhe_suicidewatch\n                                    ], dim=1)\n#             mhe_total = torch.unsqueeze(mhe_depression, 1) # 512,1,1024\n#             del mhe_depression, mhe_autism, mhe_ptsd, mhe_EDAnonymous, mhe_addiction, mhe_adhd, mhe_alcoholism, mhe_anxiety, mhe_bipolarreddit, mhe_bpd, mhe_healthanxiety, mhe_lonely, mhe_schizophrenia, mhe_socialanxiety, mhe_suicidewatch\n#             gc.collect()\n        \n            ## forward + backward + optimize\n            pred1 = net(inputs, inputs_roberta, mhe_total)\n            \n            loss1 = loss_fn(pred1, labels.unsqueeze(1))\n            # loss2 = loss_fn(pred2,label2)\n            # loss = loss1*loss_weight+loss2\n            # loss = loss1\n           \n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            loss1.backward()\n            optimizer.step()\n\n            avg_loss += loss1.item()\n\n        net.eval()\n        \n        valid_preds = np.zeros((len(val_idx),))\n        true_label = np.zeros((len(val_idx),))\n\n        avg_val_loss = 0.0\n\n        for j, data in enumerate(val_loader):\n            \n            # get the inputs\n            inputs, inputs_roberta, labels = data\n            inputs, inputs_roberta, labels = inputs.cuda(), inputs_roberta.cuda(), labels.cuda()\n            \n            mhe_depression = np.tile(mhe_depression_np,(inputs.shape[0],1)) # 512,1024\n            mhe_autism = np.tile(mhe_autism_np,(inputs.shape[0],1)) # 512,1024\n            mhe_ptsd = np.tile(mhe_ptsd_np,(inputs.shape[0],1)) # 512,1024 \n            mhe_EDAnonymous = np.tile(mhe_EDAnonymous_np,(inputs.shape[0],1)) # 512,1024\n            mhe_addiction = np.tile(mhe_addiction_np,(inputs.shape[0],1)) # 512,1024\n            mhe_adhd = np.tile(mhe_adhd_np,(inputs.shape[0],1)) # 512,1024             \n            mhe_alcoholism = np.tile(mhe_alcoholism_np,(inputs.shape[0],1)) # 512,1024\n            mhe_anxiety = np.tile(mhe_anxiety_np,(inputs.shape[0],1)) # 512,1024\n            mhe_bipolarreddit = np.tile(mhe_bipolarreddit_np,(inputs.shape[0],1)) # 512,1024  \n            mhe_bpd = np.tile(mhe_bpd_np,(inputs.shape[0],1)) # 512,1024\n            mhe_healthanxiety = np.tile(mhe_healthanxiety_np,(inputs.shape[0],1)) # 512,1024\n            mhe_lonely = np.tile(mhe_lonely_np,(inputs.shape[0],1)) # 512,1024             \n            mhe_schizophrenia = np.tile(mhe_schizophrenia_np,(inputs.shape[0],1)) # 512,1024\n            mhe_socialanxiety = np.tile(mhe_socialanxiety_np,(inputs.shape[0],1)) # 512,1024\n            mhe_suicidewatch = np.tile(mhe_suicidewatch_np,(inputs.shape[0],1)) # 512,1024            \n            \n            mhe_depression = torch.tensor(mhe_depression, dtype=torch.float).cuda()\n            mhe_autism = torch.tensor(mhe_autism, dtype=torch.float).cuda()\n            mhe_ptsd = torch.tensor(mhe_ptsd, dtype=torch.float).cuda()\n            mhe_EDAnonymous = torch.tensor(mhe_EDAnonymous, dtype=torch.float).cuda()\n            mhe_addiction = torch.tensor(mhe_addiction, dtype=torch.float).cuda()\n            mhe_adhd = torch.tensor(mhe_adhd, dtype=torch.float).cuda()\n            mhe_alcoholism = torch.tensor(mhe_alcoholism, dtype=torch.float).cuda()\n            mhe_anxiety = torch.tensor(mhe_anxiety, dtype=torch.float).cuda()\n            mhe_bipolarreddit = torch.tensor(mhe_bipolarreddit, dtype=torch.float).cuda()   \n            mhe_bpd = torch.tensor(mhe_bpd, dtype=torch.float).cuda()\n            mhe_healthanxiety = torch.tensor(mhe_healthanxiety, dtype=torch.float).cuda()\n            mhe_lonely = torch.tensor(mhe_lonely, dtype=torch.float).cuda()\n            mhe_schizophrenia = torch.tensor(mhe_schizophrenia, dtype=torch.float).cuda()\n            mhe_socialanxiety = torch.tensor(mhe_socialanxiety, dtype=torch.float).cuda()\n            mhe_suicidewatch = torch.tensor(mhe_suicidewatch, dtype=torch.float).cuda()\n  \n            mhe_total = torch.stack([mhe_depression, \n                                     mhe_autism, \n                                     mhe_ptsd,\n                                     mhe_EDAnonymous,\n                                     mhe_addiction,\n                                     mhe_adhd,\n                                     mhe_alcoholism,\n                                     mhe_anxiety,\n                                     mhe_bipolarreddit,\n                                     mhe_bpd,\n                                     mhe_healthanxiety,\n                                     mhe_lonely,\n                                     mhe_schizophrenia,\n                                     mhe_socialanxiety,\n                                     mhe_suicidewatch\n                                    ], dim=1)\n#             mhe_total = torch.unsqueeze(mhe_depression, 1) # 512,1,1024\n#             del mhe_depression, mhe_autism, mhe_ptsd, mhe_EDAnonymous, mhe_addiction, mhe_adhd, mhe_alcoholism, mhe_anxiety, mhe_bipolarreddit, mhe_bpd, mhe_healthanxiety, mhe_lonely, mhe_schizophrenia, mhe_socialanxiety, mhe_suicidewatch\n#             gc.collect()\n    \n            ## forward + backward + optimize\n            pred1 = net(inputs, inputs_roberta, mhe_total)\n    \n            loss1_val = loss_fn(pred1, labels.unsqueeze(1))\n\n            avg_val_loss += loss1_val.item()\n            # (torch.argmax(y_pred, 1) == torch.argmax(y_test, 1)).float().mean()\n            \n            valid_preds[j * BATCH_SIZE:(j+1) * BATCH_SIZE] = (pred1.squeeze().cpu().detach().numpy()>=0.5).astype(float)\n            # true_label[j * BATCH_SIZE:(j+1) * BATCH_SIZE]  = torch.argmax(labels, 1).cpu().detach().numpy()\n            true_label[j * BATCH_SIZE:(j+1) * BATCH_SIZE]  = labels.cpu().detach().numpy()\n            \n        elapsed_time = time.time() - start_time \n\n        print('Epoch {}/{} \\t loss={:.4f}\\t val_loss={:.4f} \\t val_f1_score={:.4f} \\t time={:.2f}s'.format(\n                        epoch+1, EPOCHS, avg_loss/len(train_loader),avg_val_loss/len(val_loader), f1_score(true_label, valid_preds, average='micro'), elapsed_time))\n        val_f1_epoch.append(f1_score(true_label, valid_preds, average='micro'))\n        \n        ## inference\n        result = list()\n        with torch.no_grad():\n            for (x_batch, inputs_roberta, ) in test_loader:\n                x_batch, inputs_roberta = x_batch.cuda(), inputs_roberta.cuda()\n                \n                mhe_depression = np.tile(mhe_depression_np,(x_batch.shape[0],1)) # 512,1024\n                mhe_autism = np.tile(mhe_autism_np,(x_batch.shape[0],1)) # 512,1024\n                mhe_ptsd = np.tile(mhe_ptsd_np,(x_batch.shape[0],1)) # 512,1024 \n                mhe_EDAnonymous = np.tile(mhe_EDAnonymous_np,(x_batch.shape[0],1)) # 512,1024\n                mhe_addiction = np.tile(mhe_addiction_np,(x_batch.shape[0],1)) # 512,1024\n                mhe_adhd = np.tile(mhe_adhd_np,(x_batch.shape[0],1)) # 512,1024             \n                mhe_alcoholism = np.tile(mhe_alcoholism_np,(x_batch.shape[0],1)) # 512,1024\n                mhe_anxiety = np.tile(mhe_anxiety_np,(x_batch.shape[0],1)) # 512,1024\n                mhe_bipolarreddit = np.tile(mhe_bipolarreddit_np,(x_batch.shape[0],1)) # 512,1024  \n                mhe_bpd = np.tile(mhe_bpd_np,(x_batch.shape[0],1)) # 512,1024\n                mhe_healthanxiety = np.tile(mhe_healthanxiety_np,(x_batch.shape[0],1)) # 512,1024\n                mhe_lonely = np.tile(mhe_lonely_np,(x_batch.shape[0],1)) # 512,1024             \n                mhe_schizophrenia = np.tile(mhe_schizophrenia_np,(x_batch.shape[0],1)) # 512,1024\n                mhe_socialanxiety = np.tile(mhe_socialanxiety_np,(x_batch.shape[0],1)) # 512,1024\n                mhe_suicidewatch = np.tile(mhe_suicidewatch_np,(x_batch.shape[0],1)) # 512,1024            \n\n                mhe_depression = torch.tensor(mhe_depression, dtype=torch.float).cuda()\n                mhe_autism = torch.tensor(mhe_autism, dtype=torch.float).cuda()\n                mhe_ptsd = torch.tensor(mhe_ptsd, dtype=torch.float).cuda()\n                mhe_EDAnonymous = torch.tensor(mhe_EDAnonymous, dtype=torch.float).cuda()\n                mhe_addiction = torch.tensor(mhe_addiction, dtype=torch.float).cuda()\n                mhe_adhd = torch.tensor(mhe_adhd, dtype=torch.float).cuda()\n                mhe_alcoholism = torch.tensor(mhe_alcoholism, dtype=torch.float).cuda()\n                mhe_anxiety = torch.tensor(mhe_anxiety, dtype=torch.float).cuda()\n                mhe_bipolarreddit = torch.tensor(mhe_bipolarreddit, dtype=torch.float).cuda()   \n                mhe_bpd = torch.tensor(mhe_bpd, dtype=torch.float).cuda()\n                mhe_healthanxiety = torch.tensor(mhe_healthanxiety, dtype=torch.float).cuda()\n                mhe_lonely = torch.tensor(mhe_lonely, dtype=torch.float).cuda()\n                mhe_schizophrenia = torch.tensor(mhe_schizophrenia, dtype=torch.float).cuda()\n                mhe_socialanxiety = torch.tensor(mhe_socialanxiety, dtype=torch.float).cuda()\n                mhe_suicidewatch = torch.tensor(mhe_suicidewatch, dtype=torch.float).cuda()\n\n                mhe_total = torch.stack([mhe_depression, \n                                         mhe_autism, \n                                         mhe_ptsd,\n                                         mhe_EDAnonymous,\n                                         mhe_addiction,\n                                         mhe_adhd,\n                                         mhe_alcoholism,\n                                         mhe_anxiety,\n                                         mhe_bipolarreddit,\n                                         mhe_bpd,\n                                         mhe_healthanxiety,\n                                         mhe_lonely,\n                                         mhe_schizophrenia,\n                                         mhe_socialanxiety,\n                                         mhe_suicidewatch\n                                        ], dim=1)\n#                 mhe_total = torch.unsqueeze(mhe_depression, 1) # 512,1,1024\n#                 del mhe_depression, mhe_autism, mhe_ptsd, mhe_EDAnonymous, mhe_addiction, mhe_adhd, mhe_alcoholism, mhe_anxiety, mhe_bipolarreddit, mhe_bpd, mhe_healthanxiety, mhe_lonely, mhe_schizophrenia, mhe_socialanxiety, mhe_suicidewatch\n#                 gc.collect()\n        \n                y_pred = net(x_batch, inputs_roberta, mhe_total)\n                \n                y_pred = y_pred.cpu().detach().numpy()\n                result.extend(y_pred)\n\n        test_checkpoint.append(result)\n        loss_checkpoint.append(avg_val_loss)\n        \n        \n    final_test.append(test_checkpoint[np.argmin(loss_checkpoint)])\n    val_f1_score.append(val_f1_epoch[np.argmin(loss_checkpoint)])\n    with open(\"final_test_{}\".format(fold_), \"wb\") as fp: \n        pickle.dump(final_test, fp)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # oof = np.zeros(len(x_train)*NUM_MODEL)\n# final_test = list()\n# val_f1_score = list()\n\n# NFOLDS = 5\n# # folds = KFold(n_splits=NFOLDS, shuffle=True, random_state=SEED)\n\n# # for fold_, (trn_idx, val_idx) in enumerate(folds.split(x_train)):\n\n# skf = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=SEED)\n\n# for fold_, (trn_idx, val_idx) in enumerate(skf.split(x_train, y_train)):\n        \n#     print(\"Fold: {}/{}\".format(fold_ + 1, NFOLDS))\n     \n#     x_train_fold = x_train[trn_idx]\n#     x_val = x_train[val_idx]\n#     y_train_fold = y_train[trn_idx]\n#     y_val = y_train[val_idx]\n    \n#     x_train_fold = torch.tensor(x_train_fold, dtype=torch.long).cuda()\n#     x_val = torch.tensor(x_val, dtype=torch.long).cuda()\n#     y_train_fold = torch.tensor(y_train_fold, dtype=torch.float).cuda()\n#     y_val = torch.tensor(y_val, dtype=torch.float).cuda()\n    \n#     train_data = torch.utils.data.TensorDataset(x_train_fold, y_train_fold)\n#     val_data = torch.utils.data.TensorDataset(x_val, y_val)\n\n#     train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n#     val_loader = torch.utils.data.DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n\n#     del x_train_fold, x_val, y_train_fold, train_data, val_data\n#     gc.collect()\n\n\n#     net = NeuralNet(crawl_matrix, 256, 1)\n#     net.cuda()\n#     loss_fn = torch.nn.BCELoss(reduction='mean')\n#     # loss_fn = nn.CrossEntropyLoss()\n#     # optimizer = torch.optim.Adam(net.parameters(), lr=0.002)\n#     optimizer = torch.optim.AdamW(params =  net.parameters(), lr=0.002, weight_decay=1e-7)\n\n#     test_checkpoint = list()\n#     loss_checkpoint = list()\n#     val_f1_epoch = list()\n    \n#     for epoch in range(EPOCHS): \n        \n#         start_time = time.time()\n\n#         avg_loss = 0.0\n        \n#         net.train()\n#         for i, data in enumerate(train_loader):\n            \n#             # get the inputs\n#             inputs, labels = data\n            \n#             mhe_depression = np.tile(mhe_depression_np,(inputs.shape[0],1)) # 512,1024\n#             mhe_autism = np.tile(mhe_autism_np,(inputs.shape[0],1)) # 512,1024\n#             mhe_ptsd = np.tile(mhe_ptsd_np,(inputs.shape[0],1)) # 512,1024 \n            \n#             mhe_depression = torch.tensor(mhe_depression, dtype=torch.float).cuda()\n#             mhe_autism = torch.tensor(mhe_autism, dtype=torch.float).cuda()\n#             mhe_ptsd = torch.tensor(mhe_ptsd, dtype=torch.float).cuda()\n            \n#             mhe_total = torch.stack([mhe_depression, mhe_autism, mhe_ptsd], dim=1)\n#             # mhe_depression = torch.unsqueeze(mhe_depression, 1) # 512,1,1024\n            \n#             ## forward + backward + optimize\n#             pred1 = net(inputs, mhe_total)\n            \n#             loss1 = loss_fn(pred1, labels.unsqueeze(1))\n#             # loss2 = loss_fn(pred2,label2)\n#             # loss = loss1*loss_weight+loss2\n#             # loss = loss1\n           \n#             # zero the parameter gradients\n#             optimizer.zero_grad()\n\n#             loss1.backward()\n#             optimizer.step()\n\n#             avg_loss += loss1.item()\n\n#         net.eval()\n        \n#         valid_preds = np.zeros((len(y_val),))\n#         true_label = np.zeros((len(y_val),))\n\n#         avg_val_loss = 0.0\n\n#         for j, data in enumerate(val_loader):\n            \n#             # get the inputs\n#             inputs, labels = data\n            \n#             mhe_depression = np.tile(mhe_depression_np,(inputs.shape[0],1)) # 512,1024\n#             mhe_autism = np.tile(mhe_autism_np,(inputs.shape[0],1)) # 512,1024\n#             mhe_ptsd = np.tile(mhe_ptsd_np,(inputs.shape[0],1)) # 512,1024 \n            \n#             mhe_depression = torch.tensor(mhe_depression, dtype=torch.float).cuda()\n#             mhe_autism = torch.tensor(mhe_autism, dtype=torch.float).cuda()\n#             mhe_ptsd = torch.tensor(mhe_ptsd, dtype=torch.float).cuda()\n            \n#             mhe_total = torch.stack([mhe_depression, mhe_autism, mhe_ptsd], dim=1)\n#             # mhe_depression = torch.unsqueeze(mhe_depression, 1) # 512,1,1024\n            \n#             ## forward + backward + optimize\n#             pred1 = net(inputs, mhe_total)\n            \n#             loss1_val = loss_fn(pred1, labels.unsqueeze(1))\n\n#             avg_val_loss += loss1_val.item()\n#             # (torch.argmax(y_pred, 1) == torch.argmax(y_test, 1)).float().mean()\n            \n#             valid_preds[j * BATCH_SIZE:(j+1) * BATCH_SIZE] = (pred1.squeeze().cpu().detach().numpy()>=0.5).astype(float)\n#             # true_label[j * BATCH_SIZE:(j+1) * BATCH_SIZE]  = torch.argmax(labels, 1).cpu().detach().numpy()\n#             true_label[j * BATCH_SIZE:(j+1) * BATCH_SIZE]  = labels.cpu().detach().numpy()\n            \n#         elapsed_time = time.time() - start_time \n\n#         print('Epoch {}/{} \\t loss={:.4f}\\t val_loss={:.4f} \\t val_f1_score={:.4f} \\t time={:.2f}s'.format(\n#                         epoch+1, EPOCHS, avg_loss/len(train_loader),avg_val_loss/len(val_loader), f1_score(true_label, valid_preds, average='micro'), elapsed_time))\n#         val_f1_epoch.append(f1_score(true_label, valid_preds, average='micro'))\n        \n#         ## inference\n#         result = list()\n#         with torch.no_grad():\n#             for (x_batch,) in test_loader:\n                \n#                 mhe_depression = np.tile(mhe_depression_np,(x_batch.shape[0],1)) # 512,1024\n#                 mhe_autism = np.tile(mhe_autism_np,(x_batch.shape[0],1)) # 512,1024\n#                 mhe_ptsd = np.tile(mhe_ptsd_np,(x_batch.shape[0],1)) # 512,1024 \n\n#                 mhe_depression = torch.tensor(mhe_depression, dtype=torch.float).cuda()\n#                 mhe_autism = torch.tensor(mhe_autism, dtype=torch.float).cuda()\n#                 mhe_ptsd = torch.tensor(mhe_ptsd, dtype=torch.float).cuda()\n\n#                 mhe_total = torch.stack([mhe_depression, mhe_autism, mhe_ptsd], dim=1)\n            \n#                 y_pred = net(x_batch, mhe_total)\n#                 y_pred = y_pred.cpu().detach().numpy()\n#                 result.extend(y_pred)\n\n#         test_checkpoint.append(result)\n#         loss_checkpoint.append(avg_val_loss)\n        \n        \n#     final_test.append(test_checkpoint[np.argmin(loss_checkpoint)])\n#     val_f1_score.append(val_f1_epoch[np.argmin(loss_checkpoint)])\n#     with open(\"final_test_{}\".format(fold_), \"wb\") as fp: \n#         pickle.dump(final_test, fp)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('mean val f1 score:', np.mean(val_f1_score))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class callback:\n#     def __init__(self):\n#         self.score = list()\n#         self.model = list()\n#         self.data = list()\n    \n#     def put(self, model,data, score):\n#         self.score.append(score)\n#         self.model.append(model)\n#         self.data.append(data)\n\n#     def get_model(self):\n#         ind = np.argmin(self.score)\n#         return self.model[ind]\n#     def get_data(self):\n#         ind = np.argmin(self.score)\n#         return self.data[ind]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, recall_score, precision_score\n\ndef threshold_search_fold(y_true, y_proba):\n\n    binary_best_threshold = 0\n    binary_best_score = 0\n    \n    for threshold in tqdm([i * 0.01 for i in range(100)], disable=True):\n \n        binary_score = f1_score(y_true, np.where(y_proba>=threshold , 1 ,0), average='micro')\n        if binary_score > binary_best_score:\n            binary_best_threshold = threshold\n            binary_best_score = binary_score\n            \n    recall = recall_score(y_true, np.where(y_proba>=binary_best_threshold , 1 ,0), average='micro')\n    precission = precision_score(y_true, np.where(y_proba>=binary_best_threshold , 1 ,0), average='micro')\n    print('best_threshold_recall:', recall)\n    print('best_threshold_precision:', precission)\n    \n    search_result = {'f1_binary_threshold': binary_best_threshold, 'f1_binary': binary_best_score,}\n    return search_result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_prob = np.mean(final_test, axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"search_resutls = threshold_search_fold(test_df.label.values, predicted_prob)\nsearch_resutls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_prob = (predicted_prob>=0.5).astype(float)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_score(test_df.label.values, predicted_prob, average='micro')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}